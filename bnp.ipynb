{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost and GA with GLPK\n",
    "This notebook contains the implementation of a Genetic Algorithm to carry out feature selection. This hasn't produced a reasonable result however (in fact, it can't find a tree), as it appears to have selected too many features for use with BNP-OCT (35 features currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arman/Documents/Arman/JHU/Assurance/optimaltree-master_2/lsopt/_base.py:639: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if _bin[0][r] is 1:\n",
      "/Users/arman/Documents/Arman/JHU/Assurance/optimaltree-master_2/lsopt/_base.py:671: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if _bin[0][r] is 0:\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "# from lsopt.tree import OldOptimalTreeClassifier ## OCT proposed by Bertsimas & Dunn\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree \n",
    "\n",
    "import graphviz\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phy_same</th>\n",
       "      <th>phy_count</th>\n",
       "      <th>period</th>\n",
       "      <th>periodadmt</th>\n",
       "      <th>age</th>\n",
       "      <th>alife</th>\n",
       "      <th>provider_InscClaimAmtReimbursed_mean</th>\n",
       "      <th>provider_DeductibleAmtPaid_mean</th>\n",
       "      <th>provider_NoOfMonths_PartACov_mean</th>\n",
       "      <th>provider_NoOfMonths_PartBCov_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>diag1_OPAnnualDeductibleAmt_mean</th>\n",
       "      <th>diag1_InscClaimAmtReimbursed_std</th>\n",
       "      <th>diag1_DeductibleAmtPaid_std</th>\n",
       "      <th>diag1_NoOfMonths_PartACov_std</th>\n",
       "      <th>diag1_NoOfMonths_PartBCov_std</th>\n",
       "      <th>diag1_IPAnnualReimbursementAmt_std</th>\n",
       "      <th>diag1_IPAnnualDeductibleAmt_std</th>\n",
       "      <th>diag1_OPAnnualReimbursementAmt_std</th>\n",
       "      <th>diag1_OPAnnualDeductibleAmt_std</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.240000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4185.600000</td>\n",
       "      <td>213.600000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>543.045084</td>\n",
       "      <td>3482.066310</td>\n",
       "      <td>161.353027</td>\n",
       "      <td>0.569945</td>\n",
       "      <td>0.424192</td>\n",
       "      <td>12941.552350</td>\n",
       "      <td>1205.297144</td>\n",
       "      <td>2450.076771</td>\n",
       "      <td>661.506672</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.439394</td>\n",
       "      <td>1.530303</td>\n",
       "      <td>3.674242</td>\n",
       "      <td>2.424242</td>\n",
       "      <td>71.371212</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>4588.409091</td>\n",
       "      <td>502.166667</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>11.871212</td>\n",
       "      <td>...</td>\n",
       "      <td>676.313985</td>\n",
       "      <td>4017.871066</td>\n",
       "      <td>260.257069</td>\n",
       "      <td>0.726572</td>\n",
       "      <td>0.653285</td>\n",
       "      <td>12620.604410</td>\n",
       "      <td>1226.306633</td>\n",
       "      <td>3369.338617</td>\n",
       "      <td>848.213675</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.818792</td>\n",
       "      <td>1.604027</td>\n",
       "      <td>1.429530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.516779</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>350.134228</td>\n",
       "      <td>2.080537</td>\n",
       "      <td>11.865772</td>\n",
       "      <td>11.959732</td>\n",
       "      <td>...</td>\n",
       "      <td>694.246881</td>\n",
       "      <td>1536.290845</td>\n",
       "      <td>113.086257</td>\n",
       "      <td>0.667719</td>\n",
       "      <td>0.577420</td>\n",
       "      <td>11016.516940</td>\n",
       "      <td>1111.592405</td>\n",
       "      <td>2972.377916</td>\n",
       "      <td>808.138208</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.731330</td>\n",
       "      <td>1.599142</td>\n",
       "      <td>1.088412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.783691</td>\n",
       "      <td>0.996567</td>\n",
       "      <td>241.124463</td>\n",
       "      <td>3.175966</td>\n",
       "      <td>11.907296</td>\n",
       "      <td>11.939914</td>\n",
       "      <td>...</td>\n",
       "      <td>630.805985</td>\n",
       "      <td>1234.005090</td>\n",
       "      <td>91.141252</td>\n",
       "      <td>0.657071</td>\n",
       "      <td>0.565930</td>\n",
       "      <td>10021.329570</td>\n",
       "      <td>957.701391</td>\n",
       "      <td>2727.944083</td>\n",
       "      <td>737.419878</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.736111</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>70.583333</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>468.194444</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>606.550334</td>\n",
       "      <td>1519.425993</td>\n",
       "      <td>103.302166</td>\n",
       "      <td>0.626542</td>\n",
       "      <td>0.520122</td>\n",
       "      <td>10565.761430</td>\n",
       "      <td>1126.358206</td>\n",
       "      <td>2486.827069</td>\n",
       "      <td>682.279276</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2.548387</td>\n",
       "      <td>1.548387</td>\n",
       "      <td>2.806452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>127.741935</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>539.926413</td>\n",
       "      <td>1278.578369</td>\n",
       "      <td>105.316369</td>\n",
       "      <td>0.642724</td>\n",
       "      <td>0.506470</td>\n",
       "      <td>10069.067870</td>\n",
       "      <td>1048.496358</td>\n",
       "      <td>2331.087492</td>\n",
       "      <td>676.226785</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>544.784235</td>\n",
       "      <td>589.615472</td>\n",
       "      <td>61.510304</td>\n",
       "      <td>0.690826</td>\n",
       "      <td>0.473344</td>\n",
       "      <td>10885.075840</td>\n",
       "      <td>1026.840019</td>\n",
       "      <td>2547.341333</td>\n",
       "      <td>723.822292</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>613.157895</td>\n",
       "      <td>4778.012673</td>\n",
       "      <td>463.684066</td>\n",
       "      <td>0.600751</td>\n",
       "      <td>0.710275</td>\n",
       "      <td>13241.321690</td>\n",
       "      <td>1469.095843</td>\n",
       "      <td>3203.267596</td>\n",
       "      <td>911.406530</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>566.953462</td>\n",
       "      <td>2506.463260</td>\n",
       "      <td>131.832995</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.354062</td>\n",
       "      <td>11262.841610</td>\n",
       "      <td>1196.045563</td>\n",
       "      <td>2691.729344</td>\n",
       "      <td>736.415563</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2.634921</td>\n",
       "      <td>1.539683</td>\n",
       "      <td>1.349206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.873016</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>204.444444</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>11.809524</td>\n",
       "      <td>11.809524</td>\n",
       "      <td>...</td>\n",
       "      <td>587.854714</td>\n",
       "      <td>1114.462613</td>\n",
       "      <td>97.400585</td>\n",
       "      <td>0.599785</td>\n",
       "      <td>0.533154</td>\n",
       "      <td>9713.456656</td>\n",
       "      <td>1014.932899</td>\n",
       "      <td>2579.061940</td>\n",
       "      <td>707.121804</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phy_same  phy_count    period  periodadmt        age     alife  \\\n",
       "0     2.960000   1.600000  1.440000    1.000000  80.240000  1.000000   \n",
       "1     2.439394   1.530303  3.674242    2.424242  71.371212  0.992424   \n",
       "2     2.818792   1.604027  1.429530    0.000000  73.516779  0.993289   \n",
       "3     2.731330   1.599142  1.088412    0.000000  71.783691  0.996567   \n",
       "4     2.736111   1.527778  0.958333    0.222222  70.583333  0.986111   \n",
       "...        ...        ...       ...         ...        ...       ...   \n",
       "1004  2.548387   1.548387  2.806452    0.000000  75.677419  1.000000   \n",
       "1005  2.500000   1.500000  0.100000    0.000000  78.000000  1.000000   \n",
       "1006  3.000000   2.000000  0.000000    0.000000  74.000000  1.000000   \n",
       "1007  2.333333   1.333333  2.266667    0.000000  73.933333  1.000000   \n",
       "1008  2.634921   1.539683  1.349206    0.000000  77.873016  0.984127   \n",
       "\n",
       "      provider_InscClaimAmtReimbursed_mean  provider_DeductibleAmtPaid_mean  \\\n",
       "0                              4185.600000                       213.600000   \n",
       "1                              4588.409091                       502.166667   \n",
       "2                               350.134228                         2.080537   \n",
       "3                               241.124463                         3.175966   \n",
       "4                               468.194444                        45.333333   \n",
       "...                                    ...                              ...   \n",
       "1004                            127.741935                         1.612903   \n",
       "1005                             72.000000                         0.000000   \n",
       "1006                             50.000000                         0.000000   \n",
       "1007                            296.000000                         0.000000   \n",
       "1008                            204.444444                         0.793651   \n",
       "\n",
       "      provider_NoOfMonths_PartACov_mean  provider_NoOfMonths_PartBCov_mean  \\\n",
       "0                             12.000000                          12.000000   \n",
       "1                             11.818182                          11.871212   \n",
       "2                             11.865772                          11.959732   \n",
       "3                             11.907296                          11.939914   \n",
       "4                             11.833333                          11.833333   \n",
       "...                                 ...                                ...   \n",
       "1004                          12.000000                          12.000000   \n",
       "1005                          12.000000                          12.000000   \n",
       "1006                          12.000000                          12.000000   \n",
       "1007                          12.000000                          12.000000   \n",
       "1008                          11.809524                          11.809524   \n",
       "\n",
       "      ...  diag1_OPAnnualDeductibleAmt_mean  diag1_InscClaimAmtReimbursed_std  \\\n",
       "0     ...                        543.045084                       3482.066310   \n",
       "1     ...                        676.313985                       4017.871066   \n",
       "2     ...                        694.246881                       1536.290845   \n",
       "3     ...                        630.805985                       1234.005090   \n",
       "4     ...                        606.550334                       1519.425993   \n",
       "...   ...                               ...                               ...   \n",
       "1004  ...                        539.926413                       1278.578369   \n",
       "1005  ...                        544.784235                        589.615472   \n",
       "1006  ...                        613.157895                       4778.012673   \n",
       "1007  ...                        566.953462                       2506.463260   \n",
       "1008  ...                        587.854714                       1114.462613   \n",
       "\n",
       "      diag1_DeductibleAmtPaid_std  diag1_NoOfMonths_PartACov_std  \\\n",
       "0                      161.353027                       0.569945   \n",
       "1                      260.257069                       0.726572   \n",
       "2                      113.086257                       0.667719   \n",
       "3                       91.141252                       0.657071   \n",
       "4                      103.302166                       0.626542   \n",
       "...                           ...                            ...   \n",
       "1004                   105.316369                       0.642724   \n",
       "1005                    61.510304                       0.690826   \n",
       "1006                   463.684066                       0.600751   \n",
       "1007                   131.832995                       0.726815   \n",
       "1008                    97.400585                       0.599785   \n",
       "\n",
       "      diag1_NoOfMonths_PartBCov_std  diag1_IPAnnualReimbursementAmt_std  \\\n",
       "0                          0.424192                        12941.552350   \n",
       "1                          0.653285                        12620.604410   \n",
       "2                          0.577420                        11016.516940   \n",
       "3                          0.565930                        10021.329570   \n",
       "4                          0.520122                        10565.761430   \n",
       "...                             ...                                 ...   \n",
       "1004                       0.506470                        10069.067870   \n",
       "1005                       0.473344                        10885.075840   \n",
       "1006                       0.710275                        13241.321690   \n",
       "1007                       0.354062                        11262.841610   \n",
       "1008                       0.533154                         9713.456656   \n",
       "\n",
       "      diag1_IPAnnualDeductibleAmt_std  diag1_OPAnnualReimbursementAmt_std  \\\n",
       "0                         1205.297144                         2450.076771   \n",
       "1                         1226.306633                         3369.338617   \n",
       "2                         1111.592405                         2972.377916   \n",
       "3                          957.701391                         2727.944083   \n",
       "4                         1126.358206                         2486.827069   \n",
       "...                               ...                                 ...   \n",
       "1004                      1048.496358                         2331.087492   \n",
       "1005                      1026.840019                         2547.341333   \n",
       "1006                      1469.095843                         3203.267596   \n",
       "1007                      1196.045563                         2691.729344   \n",
       "1008                      1014.932899                         2579.061940   \n",
       "\n",
       "      diag1_OPAnnualDeductibleAmt_std  PotentialFraud  \n",
       "0                          661.506672       Not-Fraud  \n",
       "1                          848.213675           Fraud  \n",
       "2                          808.138208       Not-Fraud  \n",
       "3                          737.419878           Fraud  \n",
       "4                          682.279276       Not-Fraud  \n",
       "...                               ...             ...  \n",
       "1004                       676.226785       Not-Fraud  \n",
       "1005                       723.822292       Not-Fraud  \n",
       "1006                       911.406530       Not-Fraud  \n",
       "1007                       736.415563       Not-Fraud  \n",
       "1008                       707.121804       Not-Fraud  \n",
       "\n",
       "[1009 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_fraud = './data/fraud_data_m_oct_ready.csv'\n",
    "fraud_data = pd.read_csv(data_path_fraud)\n",
    "fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fraud_data.iloc[:, 0:47].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fraud_data[\"PotentialFraud\"].apply(lambda val: 0 if val == \"Not-Fraud\" else 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.56%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]    \n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.005, n=41, Accuracy: 93.56%\n",
      "Thresh=0.009, n=40, Accuracy: 94.06%\n",
      "Thresh=0.009, n=39, Accuracy: 94.06%\n",
      "Thresh=0.009, n=38, Accuracy: 94.06%\n",
      "Thresh=0.010, n=37, Accuracy: 94.06%\n",
      "Thresh=0.011, n=36, Accuracy: 94.55%\n",
      "Thresh=0.011, n=35, Accuracy: 94.06%\n",
      "Thresh=0.011, n=34, Accuracy: 94.06%\n",
      "Thresh=0.012, n=33, Accuracy: 95.05%\n",
      "Thresh=0.012, n=32, Accuracy: 94.06%\n",
      "Thresh=0.012, n=31, Accuracy: 95.54%\n",
      "Thresh=0.012, n=30, Accuracy: 94.06%\n",
      "Thresh=0.013, n=29, Accuracy: 95.05%\n",
      "Thresh=0.013, n=28, Accuracy: 93.56%\n",
      "Thresh=0.014, n=27, Accuracy: 94.06%\n",
      "Thresh=0.014, n=26, Accuracy: 94.06%\n",
      "Thresh=0.014, n=25, Accuracy: 94.06%\n",
      "Thresh=0.015, n=24, Accuracy: 95.54%\n",
      "Thresh=0.015, n=23, Accuracy: 94.55%\n",
      "Thresh=0.016, n=22, Accuracy: 93.56%\n",
      "Thresh=0.017, n=21, Accuracy: 94.06%\n",
      "Thresh=0.017, n=20, Accuracy: 94.55%\n",
      "Thresh=0.020, n=19, Accuracy: 94.06%\n",
      "Thresh=0.020, n=18, Accuracy: 93.56%\n",
      "Thresh=0.020, n=17, Accuracy: 94.55%\n",
      "Thresh=0.022, n=16, Accuracy: 93.56%\n",
      "Thresh=0.023, n=15, Accuracy: 93.56%\n",
      "Thresh=0.024, n=14, Accuracy: 93.07%\n",
      "Thresh=0.025, n=13, Accuracy: 93.07%\n",
      "Thresh=0.025, n=12, Accuracy: 92.57%\n",
      "Thresh=0.026, n=11, Accuracy: 94.55%\n",
      "Thresh=0.026, n=10, Accuracy: 94.06%\n",
      "Thresh=0.029, n=9, Accuracy: 94.06%\n",
      "Thresh=0.030, n=8, Accuracy: 94.55%\n",
      "Thresh=0.032, n=7, Accuracy: 95.05%\n",
      "Thresh=0.045, n=6, Accuracy: 93.56%\n",
      "Thresh=0.046, n=5, Accuracy: 94.06%\n",
      "Thresh=0.047, n=4, Accuracy: 93.07%\n",
      "Thresh=0.063, n=3, Accuracy: 93.07%\n",
      "Thresh=0.080, n=2, Accuracy: 91.58%\n",
      "Thresh=0.127, n=1, Accuracy: 90.59%\n"
     ]
    }
   ],
   "source": [
    "thresholds = sort(model.feature_importances_)\n",
    "max_acc = -1\n",
    "true_thresh = -1\n",
    "for thresh in thresholds:\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    \n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    if accuracy >= max_acc and select_X_train.shape[1] < 20:\n",
    "        max_acc = accuracy\n",
    "        true_thresh = thresh\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032147862\n"
     ]
    }
   ],
   "source": [
    "print(true_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "\n",
    "# OCT parameters\n",
    "max_depth = 3\n",
    "min_samples_leaf = 7\n",
    "alpha = 0.005\n",
    "time_limit = 10 # minute\n",
    "mip_gap_tol = 0.05  # optimal gap percentage\n",
    "mip_focus = 'balance'\n",
    "mip_polish_time = None\n",
    "warm_start = False\n",
    "log_file = None\n",
    "fp_heur = True\n",
    "backtrack = \"bestb\"\n",
    "\n",
    "# Construct BNP-OCT classifier\n",
    "selection_model = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"glpk\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'fp_heur': fp_heur,\n",
    "                                                  'backtrack': backtrack\n",
    "                                                  }\n",
    "                                  )\n",
    "\n",
    "names = []\n",
    "for i in range(len(model.feature_importances_)):\n",
    "    if model.feature_importances_[i] >= true_thresh:\n",
    "        names.append(fraud_data.iloc[:, [i]].columns[0])\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of below code\n",
    "Alright, there's a few functions here, so lets go through them one by one.\n",
    "\n",
    "### Split\n",
    "This one is pretty straitforward, its the one that actually splits the data into a training set and a testing set\n",
    "\n",
    "### acc_score\n",
    "Returns the accuracy of each model\n",
    "\n",
    "### plot\n",
    "For plotting any results of the model, if I need to visualize it\n",
    "\n",
    "### initialization_of_population\n",
    "To initialize a random population.\n",
    "\n",
    "### fitness_score\n",
    "Returns the best parents for the next run, along with their fitness scores\n",
    "\n",
    "### selection\n",
    "Selects the best parents at the end of every run\n",
    "\n",
    "### crossover\n",
    "Picks half of the first parents, and half of the second\n",
    "\n",
    "### mutation\n",
    "Randomly flip the a feature from True to False (holding true to the principle of the genetic algorithm)\n",
    "\n",
    "### generations\n",
    "Executes all the above functions for the specified number of generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df,label):\n",
    "    selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "    X_tr = select_X_train\n",
    "    X_te = X_test\n",
    "    Y_tr = y_train\n",
    "    Y_te = y_test\n",
    "    return X_tr, X_te, Y_tr, Y_te\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import random\n",
    "\n",
    "classifiers = ['LinearSVM', 'RadialSVM', \n",
    "               'Logistic',  'RandomForest', \n",
    "               'AdaBoost',  'DecisionTree', \n",
    "               'KNeighbors','GradientBoosting', 'BNP-OCT']\n",
    "\n",
    "models = [svm.SVC(kernel='linear'),\n",
    "          svm.SVC(kernel='rbf'),\n",
    "          LogisticRegression(max_iter = 1000),\n",
    "          RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "          AdaBoostClassifier(random_state = 0),\n",
    "          DecisionTreeClassifier(random_state=0),\n",
    "          KNeighborsClassifier(),\n",
    "          XGBClassifier(random_state=0),\n",
    "          BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"glpk\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'fp_heur': fp_heur,\n",
    "                                                  'backtrack': backtrack\n",
    "                                                  }\n",
    "                                  )]\n",
    "\n",
    "\n",
    "def acc_score(df,label):\n",
    "    Score = pd.DataFrame({\"Classifier\":classifiers})\n",
    "    j = 0\n",
    "    acc = []\n",
    "    X_train = select_X_train\n",
    "    X_test = select_X_train\n",
    "    Y_train = y_train\n",
    "    Y_test = y_train\n",
    "    for i in models:\n",
    "        model = i\n",
    "        model.fit(X_train,Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        acc.append(accuracy_score(Y_test,predictions))\n",
    "        j = j+1     \n",
    "    Score[\"Accuracy\"] = acc\n",
    "    Score.sort_values(by=\"Accuracy\", ascending=False,inplace = True)\n",
    "    Score.reset_index(drop=True, inplace=True)\n",
    "    return Score\n",
    "\n",
    "def plot(score,x,y,c = \"b\"):\n",
    "    gen = [1,2,3,4,5]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax = sns.pointplot(x=gen, y=score,color = c )\n",
    "    ax.set(xlabel=\"Generation\", ylabel=\"Accuracy\")\n",
    "    ax.set(ylim=(x,y))\n",
    "    \n",
    "def initilization_of_population(size,n_feat):\n",
    "    population = []\n",
    "    for i in range(size):\n",
    "        chromosome = np.ones(n_feat,dtype=bool)     \n",
    "        chromosome[:int(0.3*n_feat)]=False             \n",
    "        np.random.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_score(population):\n",
    "    scores = []\n",
    "    for chromosome in population:\n",
    "        logmodel.fit(select_X_train[:, chromosome],y_train)         \n",
    "        predictions = logmodel.predict(select_X_train[:, chromosome])\n",
    "        scores.append(accuracy_score(y_train,predictions))\n",
    "    scores, population = np.array(scores), np.array(population) \n",
    "    inds = np.argsort(scores)                                    \n",
    "    return list(scores[inds][::-1]), list(population[inds,:][::-1]) \n",
    "\n",
    "def selection(pop_after_fit,n_parents):\n",
    "    population_nextgen = []\n",
    "    for i in range(n_parents):\n",
    "        population_nextgen.append(pop_after_fit[i])\n",
    "    return population_nextgen\n",
    "\n",
    "\n",
    "def crossover(pop_after_sel):\n",
    "    pop_nextgen = pop_after_sel\n",
    "    for i in range(0,len(pop_after_sel),2):\n",
    "        new_par = []\n",
    "        child_1 , child_2 = pop_nextgen[i] , pop_nextgen[i+1]\n",
    "        new_par = np.concatenate((child_1[:len(child_1)//2],child_2[len(child_1)//2:]))\n",
    "        pop_nextgen.append(new_par)\n",
    "    return pop_nextgen\n",
    "\n",
    "def mutation(pop_after_cross,mutation_rate,n_feat):   \n",
    "    mutation_range = int(mutation_rate*n_feat)\n",
    "    pop_next_gen = []\n",
    "    for n in range(0,len(pop_after_cross)):\n",
    "        chromo = pop_after_cross[n]\n",
    "        rand_posi = [] \n",
    "        for i in range(0,mutation_range):\n",
    "            pos = random.randint(0,n_feat-1)\n",
    "            rand_posi.append(pos)\n",
    "        for j in rand_posi:\n",
    "            chromo[j] = not chromo[j]  \n",
    "        pop_next_gen.append(chromo)\n",
    "    return pop_next_gen\n",
    "\n",
    "def generations(df,label,size,n_feat,n_parents,mutation_rate,n_gen,X_train,\n",
    "                                   X_test, Y_train, Y_test):\n",
    "    best_chromo= []\n",
    "    best_score= []\n",
    "    population_nextgen=initilization_of_population(size,n_feat)\n",
    "    for i in range(n_gen):\n",
    "        scores, pop_after_fit = fitness_score(population_nextgen)\n",
    "        print('Best score in generation',i+1,':',scores[:1])  #2\n",
    "        pop_after_sel = selection(pop_after_fit,n_parents)\n",
    "        pop_after_cross = crossover(pop_after_sel)\n",
    "        population_nextgen = mutation(pop_after_cross,mutation_rate,n_feat)\n",
    "        best_chromo.append(pop_after_fit[0])\n",
    "        best_score.append(scores[0])\n",
    "    return best_chromo,best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of cell below\n",
    "The below cell essentially generates the accuracy of all the possible model classifiers that can be used (it appears that XGBoost is best, along with AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPSOL--GLPK LP/MIP Solver 5.0\n",
      "Parameter(s) specified in the command line:\n",
      " --tmlim 600 --mipgap 0.05 --fpump --bestb --write /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpy_gc4vvx.glpk.raw\n",
      " --wglp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpbi0rif2c.glpk.glp\n",
      " --cpxlp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpops8n487.pyomo.lp\n",
      "Reading problem data from '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpops8n487.pyomo.lp'...\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpops8n487.pyomo.lp:523330: warning: lower bound of variable 'x11' redefined\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpops8n487.pyomo.lp:523330: warning: upper bound of variable 'x11' redefined\n",
      "26210 rows, 6622 columns, 438053 non-zeros\n",
      "133 integer variables, all of which are binary\n",
      "523463 lines were read\n",
      "Writing problem data to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpbi0rif2c.glpk.glp'...\n",
      "503566 lines were written\n",
      "GLPK Integer Optimizer 5.0\n",
      "26210 rows, 6622 columns, 438053 non-zeros\n",
      "133 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "24584 rows, 6621 columns, 436427 non-zeros\n",
      "133 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.240e+03  ratio =  1.240e+03\n",
      "GM: min|aij| =  1.918e-01  max|aij| =  5.214e+00  ratio =  2.719e+01\n",
      "EQ: min|aij| =  3.698e-02  max|aij| =  1.000e+00  ratio =  2.704e+01\n",
      "2N: min|aij| =  3.125e-02  max|aij| =  1.750e+00  ratio =  5.600e+01\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 24584\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "24584 rows, 6621 columns, 436427 non-zeros\n",
      "      0: obj =   5.000000000e-03 inf =   1.644e+02 (146)\n",
      "Perturbing LP to avoid stalling [370]...\n",
      "   1335: obj =   4.016172156e+00 inf =   2.228e-06 (0) 12\n",
      "*  3066: obj =   4.999999408e-03 inf =   3.308e-04 (2531) 17\n",
      "*  4283: obj =   4.999999014e-03 inf =   4.980e-04 (1772) 12\n",
      "*  5581: obj =   4.999998752e-03 inf =   7.747e-04 (1170) 13\n",
      "Removing LP perturbation [6967]...\n",
      "*  6967: obj =   5.000000000e-03 inf =   5.982e-14 (0) 13\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+  6967: mip =     not found yet >=              -inf        (1; 0)\n",
      "Applying FPUMP heuristic...\n",
      "Pass 1\n",
      "*  3257: obj =   2.121898742e+00 inf =   6.549e-04 (2817) 29\n",
      "*  4829: obj =   1.976592039e+00 inf =   7.779e-04 (2987) 13\n",
      "*  6319: obj =   1.866011511e+00 inf =   7.655e-04 (2845) 13\n",
      "*  7742: obj =   1.788965533e+00 inf =   6.995e-04 (2694) 13\n",
      "*  9069: obj =   1.728989187e+00 inf =   6.326e-04 (2576) 10\n",
      "* 10452: obj =   1.651804911e+00 inf =   5.818e-04 (2984) 12\n",
      "* 11907: obj =   1.053339937e+00 inf =   5.382e-04 (2716) 13\n",
      "* 13258: obj =   1.042836400e+00 inf =   5.334e-04 (2686) 11\n",
      "* 14737: obj =   1.028861289e+00 inf =   5.046e-04 (2722) 12\n",
      "* 16243: obj =   1.005110076e+00 inf =   5.172e-04 (2715) 12\n",
      "* 17778: obj =   9.999794094e-01 inf =   5.611e-04 (1504) 13\n",
      "* 19375: obj =   9.999791650e-01 inf =   5.889e-04 (277) 14\n",
      "* 19633: obj =   1.000000000e+00 inf =   7.288e-14 (0) 3\n",
      "* 22679: obj =   3.016593659e+00 inf =   4.502e-04 (2559) 19\n",
      "* 23923: obj =   3.016414299e+00 inf =   5.320e-04 (2460) 9\n",
      "* 25227: obj =   3.013653611e+00 inf =   5.312e-04 (2785) 11\n",
      "* 26529: obj =   2.999992784e+00 inf =   6.487e-04 (1518) 12\n",
      "* 27499: obj =   2.999992588e+00 inf =   7.019e-04 (963) 9\n",
      "* 28619: obj =   2.999992527e+00 inf =   6.674e-04 (30) 11\n",
      "* 28651: obj =   3.000000000e+00 inf =   3.685e-14 (0)\n",
      "Pass 2\n",
      "* 30824: obj =   2.783202340e+01 inf =   5.980e-04 (2589) 18\n",
      "* 31960: obj =   2.701374053e+01 inf =   6.763e-04 (3060) 10\n",
      "* 33231: obj =   2.701368252e+01 inf =   6.308e-04 (2518) 11\n",
      "* 34730: obj =   2.367522696e+01 inf =   5.072e-04 (2299) 13\n",
      "* 36160: obj =   2.299998116e+01 inf =   5.355e-04 (1567) 13\n",
      "* 37809: obj =   2.270549703e+01 inf =   2.495e-04 (2091) 15\n",
      "* 39204: obj =   2.000000000e+01 inf =   9.644e-15 (0) 13\n",
      "* 42095: obj =   3.021781698e+00 inf =   5.643e-05 (2091) 26\n",
      "* 43386: obj =   2.947496767e+00 inf =   9.242e-05 (2291) 11\n",
      "* 44821: obj =   2.915952699e+00 inf =   7.970e-05 (1670) 12\n",
      "* 46199: obj =   2.913021456e+00 inf =   1.376e-14 (0) 12\n",
      "* 49357: obj =   1.836376772e+00 inf =   3.116e-05 (852) 27\n",
      "* 50858: obj =   1.674709797e+00 inf =   3.565e-05 (559) 12\n",
      "* 51211: obj =   1.669803216e+00 inf =   9.976e-14 (0) 3\n",
      "* 54139: obj =   1.918275956e+00 inf =   8.272e-05 (1017) 24\n",
      "* 55674: obj =   1.818700735e+00 inf =   7.097e-05 (1450) 13\n",
      "* 57166: obj =   1.593143208e+00 inf =   5.997e-05 (865) 13\n",
      "* 58001: obj =   1.582483072e+00 inf =   1.206e-15 (0) 7\n",
      "* 60553: obj =   1.612185177e+00 inf =   1.153e-04 (2084) 20\n",
      "* 61961: obj =   1.566758930e+00 inf =   1.250e-04 (2554) 9\n",
      "* 63384: obj =   1.465209828e+00 inf =   1.033e-04 (1775) 13\n",
      "* 64911: obj =   1.254581648e+00 inf =   8.828e-05 (1381) 13\n",
      "* 66762: obj =   1.037837237e+00 inf =   7.372e-05 (546) 16\n",
      "* 67088: obj =   1.032063528e+00 inf =   2.419e-15 (0) 2\n",
      "* 70296: obj =   2.475314735e+00 inf =   1.019e-04 (1179) 26\n",
      "* 71624: obj =   2.371031700e+00 inf =   1.032e-04 (1810) 12\n",
      "* 72970: obj =   2.326983594e+00 inf =   1.079e-04 (1281) 11\n",
      "* 74237: obj =   2.058032564e+00 inf =   9.691e-05 (1328) 11\n",
      "* 75345: obj =   1.849334904e+00 inf =   9.241e-05 (1355) 10\n",
      "* 76380: obj =   1.828118840e+00 inf =   9.031e-05 (1303) 9\n",
      "* 77421: obj =   1.766813563e+00 inf =   8.314e-05 (2532) 9\n",
      "* 78491: obj =   1.744368861e+00 inf =   9.010e-05 (1074) 9\n",
      "* 79562: obj =   1.629253955e+00 inf =   9.117e-05 (2298) 9\n",
      "* 80674: obj =   1.535978871e+00 inf =   9.112e-05 (2032) 10\n",
      "* 81864: obj =   1.417928534e+00 inf =   1.075e-04 (1411) 10\n",
      "* 82933: obj =   1.411487423e+00 inf =   1.187e-04 (2595) 10\n",
      "* 84160: obj =   1.389516926e+00 inf =   1.094e-04 (1118) 11\n",
      "* 85675: obj =   1.368633156e+00 inf =   1.029e-04 (142) 13\n",
      "* 86079: obj =   1.368597807e+00 inf =   8.361e-15 (0) 3\n",
      "* 89264: obj =   3.015902430e+00 inf =   1.271e-04 (583) 27\n",
      "* 90835: obj =   3.014457345e+00 inf =   2.171e-04 (609) 14\n",
      "* 92225: obj =   3.011127040e+00 inf =   2.614e-14 (0) 12\n",
      "* 95168: obj =   1.564378456e+00 inf =   1.367e-04 (2021) 22\n",
      "* 96147: obj =   1.436469737e+00 inf =   1.357e-04 (2212) 9\n",
      "* 97321: obj =   1.358846189e+00 inf =   1.222e-04 (846) 9\n",
      "* 98516: obj =   1.144989811e+00 inf =   9.881e-05 (1583) 10\n",
      "* 99765: obj =   9.387425999e-01 inf =   8.391e-05 (5) 10\n",
      "* 99769: obj =   9.387437333e-01 inf =   4.002e-14 (0)\n",
      "*102134: obj =   8.937346240e-01 inf =   1.172e-04 (2089) 19\n",
      "*103340: obj =   7.695459737e-01 inf =   1.243e-04 (1426) 11\n",
      "*104821: obj =   7.028740660e-01 inf =   8.875e-05 (484) 12\n",
      "*105402: obj =   6.939323115e-01 inf =   1.220e-15 (0) 5\n",
      "*108616: obj =   1.474691624e+00 inf =   8.077e-05 (3070) 27\n",
      "*110215: obj =   1.383901784e+00 inf =   8.126e-05 (989) 14\n",
      "*111304: obj =   1.363389312e+00 inf =   0.000e+00 (0) 10\n",
      "*114045: obj =   1.314308427e+00 inf =   9.310e-05 (845) 23\n",
      "*115262: obj =   1.314279210e+00 inf =   1.664e-04 (48) 11\n",
      "*115282: obj =   1.314279305e+00 inf =   1.076e-16 (0) 1\n",
      "*117309: obj =   4.861295492e-01 inf =   1.309e-04 (865) 14\n",
      "*118473: obj =   4.819749275e-01 inf =   1.309e-14 (0) 9\n",
      "*121453: obj =   1.420842762e+00 inf =   1.104e-04 (2185) 25\n",
      "*123051: obj =   1.341350497e+00 inf =   1.506e-04 (1156) 14\n",
      "*124531: obj =   1.314032608e+00 inf =   1.532e-04 (1996) 13\n",
      "*125989: obj =   1.294888648e+00 inf =   1.543e-04 (1157) 13\n",
      "*127004: obj =   1.287112122e+00 inf =   2.287e-14 (0) 8\n",
      "*132815: obj =   1.315029512e+00 inf =   1.211e-04 (1456) 23\n",
      "*134074: obj =   1.180005152e+00 inf =   0.000e+00 (0) 12\n",
      "Pass 3\n",
      "*137798: obj =   2.336095538e+01 inf =   1.495e-04 (1323) 32\n",
      "*140154: obj =   2.210463896e+01 inf =   9.833e-06 (1246) 21\n",
      "*140791: obj =   2.200000000e+01 inf =   1.564e-15 (0) 5\n",
      "*150832: obj =   4.242806592e-02 inf =   4.057e-05 (749) 37\n",
      "*151960: obj =   3.057538017e-02 inf =   7.372e-14 (0) 8\n",
      "Solution found by heuristic: 0.88393258427\n",
      "Pass 1\n",
      "*  3794: obj =   2.014869585e+00 inf =   5.596e-04 (2985) 32\n",
      "*  5200: obj =   1.891463555e+00 inf =   6.911e-04 (2628) 12\n",
      "*  6333: obj =   1.847410293e+00 inf =   7.510e-04 (2692) 9\n",
      "*  7432: obj =   1.772076721e+00 inf =   7.457e-04 (2475) 10\n",
      "*  8383: obj =   1.758284990e+00 inf =   7.466e-04 (2560) 8\n",
      "*  9283: obj =   1.747716269e+00 inf =   6.857e-04 (2701) 7\n",
      "* 10206: obj =   1.207950483e+00 inf =   6.472e-04 (2513) 8\n",
      "* 11216: obj =   1.190617109e+00 inf =   6.253e-04 (2623) 9\n",
      "* 12346: obj =   1.147001581e+00 inf =   5.632e-04 (2845) 9\n",
      "* 13647: obj =   1.128552414e+00 inf =   5.308e-04 (2855) 11\n",
      "* 15082: obj =   1.096813527e+00 inf =   5.174e-04 (2545) 12\n",
      "* 16597: obj =   1.083485497e+00 inf =   4.893e-04 (2783) 12\n",
      "* 18204: obj =   1.053270804e+00 inf =   4.668e-04 (2520) 14\n",
      "* 19654: obj =   1.024542097e+00 inf =   4.436e-04 (2620) 11\n",
      "* 21037: obj =   1.016834745e+00 inf =   4.453e-04 (2087) 12\n",
      "* 22225: obj =   9.999791312e-01 inf =   4.491e-04 (1798) 9\n",
      "* 23398: obj =   9.999784104e-01 inf =   5.034e-04 (1284) 10\n",
      "* 24391: obj =   1.000000000e+00 inf =   8.972e-14 (0) 8\n",
      "+  6967: mip =   8.839325843e-01 >=   5.000000000e-03  99.4% (2; 0)\n",
      "Time used: 625.9 secs.  Memory used: 74.2 Mb.\n",
      "+  6967: mip =   8.839325843e-01 >=   5.000000000e-03  99.4% (2; 0)\n",
      "TIME LIMIT EXCEEDED; SEARCH TERMINATED\n",
      "Time used:   649.2 secs\n",
      "Memory used: 141.0 Mb (147867078 bytes)\n",
      "Writing MIP solution to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpy_gc4vvx.glpk.raw'...\n",
      "32841 lines were written\n",
      "Solver running time: 649.9588329792023\n",
      "Solver termination condition: feasible\n",
      "Valid Tree : Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.998761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.944238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.909542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BNP-OCT</td>\n",
       "      <td>0.905824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RadialSVM</td>\n",
       "      <td>0.895911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.887237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.881041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classifier  Accuracy\n",
       "0      RandomForest  1.000000\n",
       "1      DecisionTree  1.000000\n",
       "2  GradientBoosting  0.998761\n",
       "3          AdaBoost  0.944238\n",
       "4        KNeighbors  0.909542\n",
       "5           BNP-OCT  0.905824\n",
       "6         RadialSVM  0.895911\n",
       "7          Logistic  0.887237\n",
       "8         LinearSVM  0.881041"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = acc_score(select_X_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPSOL--GLPK LP/MIP Solver 5.0\n",
      "Parameter(s) specified in the command line:\n",
      " --tmlim 600 --mipgap 0.05 --fpump --bestb --write /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpr8y6e8_2.glpk.raw\n",
      " --wglp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmphvzznf0f.glpk.glp\n",
      " --cpxlp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpdpodygv4.pyomo.lp\n",
      "Reading problem data from '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpdpodygv4.pyomo.lp'...\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpdpodygv4.pyomo.lp:388458: warning: lower bound of variable 'x11' redefined\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpdpodygv4.pyomo.lp:388458: warning: upper bound of variable 'x11' redefined\n",
      "20546 rows, 6608 columns, 320187 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "388577 lines were read\n",
      "Writing problem data to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmphvzznf0f.glpk.glp'...\n",
      "374358 lines were written\n",
      "GLPK Integer Optimizer 5.0\n",
      "20546 rows, 6608 columns, 320187 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "18920 rows, 6607 columns, 318561 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.240e+03  ratio =  1.240e+03\n",
      "GM: min|aij| =  1.914e-01  max|aij| =  5.226e+00  ratio =  2.731e+01\n",
      "EQ: min|aij| =  3.689e-02  max|aij| =  1.000e+00  ratio =  2.711e+01\n",
      "2N: min|aij| =  3.125e-02  max|aij| =  1.719e+00  ratio =  5.500e+01\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 18920\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "18920 rows, 6607 columns, 318561 non-zeros\n",
      "      0: obj =   5.000000000e-03 inf =   1.645e+02 (146)\n",
      "    289: obj =   4.538707865e+00 inf =   0.000e+00 (0) 2\n",
      "*   291: obj =   5.000000000e-03 inf =   0.000e+00 (0)\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+   291: mip =     not found yet >=              -inf        (1; 0)\n",
      "Applying FPUMP heuristic...\n",
      "Pass 1\n",
      "*  7008: obj =   1.067605733e+00 inf =   1.147e-04 (2518) 60\n",
      "*  9367: obj =   1.038502215e+00 inf =   1.660e-04 (2413) 19\n",
      "* 11419: obj =   1.024116425e+00 inf =   2.158e-04 (3191) 16\n",
      "* 13402: obj =   1.010742575e+00 inf =   2.717e-04 (2439) 16\n",
      "* 15446: obj =   9.999992951e-01 inf =   3.322e-04 (1133) 17\n",
      "* 16584: obj =   1.000000000e+00 inf =   1.073e-14 (0) 10\n",
      "* 21282: obj =   3.009196498e+00 inf =   2.815e-04 (1079) 36\n",
      "* 21836: obj =   3.008900222e+00 inf =   5.551e-17 (0) 5\n",
      "Pass 2\n",
      "* 33361: obj =   2.471057220e+01 inf =   1.559e-04 (2089) 40\n",
      "* 36185: obj =   1.895451743e+01 inf =   5.597e-05 (1156) 24\n",
      "* 38801: obj =   1.558578164e+01 inf =   1.276e-05 (989) 24\n",
      "* 41254: obj =   1.505938265e+01 inf =   9.013e-06 (2075) 20\n",
      "* 43789: obj =   1.503059850e+01 inf =   6.455e-06 (1627) 19\n",
      "* 44737: obj =   1.502953519e+01 inf =   5.274e-15 (0) 3\n",
      "Pass 3\n",
      "* 60860: obj =   2.058307689e+01 inf =   4.165e-05 (2446) 46\n",
      "* 62830: obj =   1.591971190e+01 inf =   2.164e-05 (2508) 19\n",
      "* 64501: obj =   1.402655407e+01 inf =   1.604e-05 (583) 14\n",
      "* 64861: obj =   1.400000000e+01 inf =   2.132e-16 (0) 3\n",
      "* 67878: obj =   4.647501224e-01 inf =   1.370e-05 (1130) 19\n",
      "* 69432: obj =   1.779904837e-01 inf =   1.299e-05 (1844) 11\n",
      "* 71272: obj =   9.422800243e-02 inf =   2.877e-05 (1749) 12\n",
      "* 72411: obj =   8.964793930e-02 inf =   8.291e-15 (0) 6\n",
      "Solution found by heuristic: 1.00752808989\n",
      "Pass 1\n",
      "*  6915: obj =   1.107154710e+00 inf =   1.229e-04 (2485) 61\n",
      "*  8390: obj =   1.073639018e+00 inf =   1.646e-04 (2282) 12\n",
      "*  9630: obj =   1.055894743e+00 inf =   2.071e-04 (2277) 11\n",
      "* 10706: obj =   1.032927951e+00 inf =   2.195e-04 (2159) 9\n",
      "* 11683: obj =   1.024618599e+00 inf =   1.896e-04 (2083) 7\n",
      "* 12633: obj =   1.021878546e+00 inf =   1.899e-04 (1761) 8\n",
      "* 13895: obj =   1.009931827e+00 inf =   2.003e-04 (1097) 10\n",
      "* 15128: obj =   1.008672739e+00 inf =   1.286e-13 (0) 10\n",
      "* 19912: obj =   3.040682651e+00 inf =   2.473e-04 (1494) 35\n",
      "* 20527: obj =   3.039355587e+00 inf =   3.128e-15 (0) 6\n",
      "* 27831: obj =   3.043059909e+00 inf =   2.894e-04 (1385) 28\n",
      "* 29425: obj =   3.041662634e+00 inf =   2.908e-04 (771) 14\n",
      "* 30945: obj =   3.039355587e+00 inf =   5.012e-14 (0) 12\n",
      "Pass 2\n",
      "* 33759: obj =   2.597666311e+01 inf =   2.702e-04 (2537) 21\n",
      "* 35614: obj =   2.153794554e+01 inf =   1.717e-04 (2277) 14\n",
      "* 37451: obj =   1.955424220e+01 inf =   6.926e-05 (2162) 15\n",
      "* 39858: obj =   1.334894448e+01 inf =   4.815e-05 (854) 20\n",
      "* 42122: obj =   1.322052376e+01 inf =   8.100e-05 (680) 21\n",
      "* 43292: obj =   1.300000000e+01 inf =   1.110e-15 (0) 10\n",
      "* 48989: obj =   1.022490037e+00 inf =   4.637e-05 (1266) 40\n",
      "* 50006: obj =   1.021840874e+00 inf =   1.441e-14 (0) 7\n",
      "* 55354: obj =   2.081220671e-01 inf =   6.393e-05 (1365) 38\n",
      "* 56750: obj =   1.427302729e-01 inf =   5.690e-15 (0) 9\n",
      "* 62455: obj =   2.687147730e-01 inf =   7.133e-05 (891) 44\n",
      "* 65205: obj =   1.448616813e-01 inf =   6.765e-05 (1453) 19\n",
      "* 68014: obj =   6.861166762e-02 inf =   6.988e-05 (1116) 20\n",
      "* 70826: obj =   5.065268795e-02 inf =   7.120e-05 (394) 19\n",
      "* 71286: obj =   5.062274225e-02 inf =   6.341e-13 (0) 3\n",
      "Pass 3\n",
      "* 90631: obj =   7.766693950e-01 inf =   3.932e-05 (2329) 28\n",
      "* 92717: obj =   2.272893314e-01 inf =   5.083e-05 (1252) 16\n",
      "* 95044: obj =   3.485813464e-02 inf =   7.193e-05 (417) 18\n",
      "* 95628: obj =   3.391356262e-02 inf =   1.761e-14 (0) 5\n",
      "*111970: obj =   1.071427831e+00 inf =   7.615e-05 (798) 45\n",
      "*112970: obj =   1.017948718e+00 inf =   4.176e-14 (0) 8\n",
      "Pass 4\n",
      "Pass 5\n",
      "+   291: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (2; 0)\n",
      "Time used: 459.8 secs.  Memory used: 51.6 Mb.\n",
      "#  7186: obj =   7.501623622e-03 inf =   0.000e+00 (309) 58 95%\n",
      "#  9017: obj =   7.554042049e-03 inf =   2.360e-16 (0) 17 98%\n",
      "+  9017: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (13; 0)\n",
      "# 16427: obj =   7.092960018e-03 inf =   0.000e+00 (1696) 51 96%\n",
      "# 18620: obj =   7.190645135e-03 inf =   0.000e+00 (1399) 21 98%\n",
      "# 20253: obj =   7.199610231e-03 inf =   0.000e+00 (914) 15 98%\n",
      "# 22367: obj =   7.277466538e-03 inf =   0.000e+00 (1378) 19 93%\n",
      "# 24383: obj =   7.296799176e-03 inf =   0.000e+00 (1222) 19 99%\n",
      "# 26462: obj =   7.331933751e-03 inf =   0.000e+00 (2260) 20 97%\n",
      "# 29000: obj =   7.348781384e-03 inf =   0.000e+00 (1633) 24 99%\n",
      "# 32293: obj =   7.363667610e-03 inf =   0.000e+00 (559) 32 99%\n",
      "# 35051: obj =   7.603941178e-03 inf =   0.000e+00 (259) 26 95%\n",
      "# 35256: obj =   7.597090095e-03 inf =   8.309e-17 (0) 2 100%\n",
      "+ 35256: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (19; 1)\n",
      "Time used: 525.8 secs.  Memory used: 52.4 Mb.\n",
      "+ 38940: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (21; 1)\n",
      "+ 42540: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (35; 2)\n",
      "# 45991: obj =   1.415183181e-01 inf =   0.000e+00 (509) 30 92%\n",
      "# 47737: obj =   1.415611139e-01 inf =   0.000e+00 (601) 16 95%\n",
      "# 49642: obj =   1.416772320e-01 inf =   0.000e+00 (853) 18 95%\n",
      "# 51459: obj =   1.423314607e-01 inf =   4.337e-19 (0) 18 99%\n",
      "+ 51459: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (37; 2)\n",
      "# 58592: obj =   5.138334283e-03 inf =   0.000e+00 (1989) 60 95%\n",
      "# 62221: obj =   5.261961953e-03 inf =   0.000e+00 (2800) 34 98%\n",
      "# 65867: obj =   5.378143900e-03 inf =   0.000e+00 (1649) 34 99%\n",
      "# 69231: obj =   5.826302099e-03 inf =   0.000e+00 (3840) 30 97%\n",
      "# 71279: obj =   5.827698782e-03 inf =   0.000e+00 (1931) 19 100%\n",
      "# 72812: obj =   5.833333333e-03 inf =   2.067e-14 (0) 15 100%\n",
      "+ 72812: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (38; 3)\n",
      "Time used: 597.9 secs.  Memory used: 53.4 Mb.\n",
      "+ 73705: mip =   1.007528090e+00 >=   5.000000000e-03  99.5% (39; 3)\n",
      "TIME LIMIT EXCEEDED; SEARCH TERMINATED\n",
      "Time used:   600.8 secs\n",
      "Memory used: 102.1 Mb (107109760 bytes)\n",
      "Writing MIP solution to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpr8y6e8_2.glpk.raw'...\n",
      "27163 lines were written\n",
      "Solver running time: 601.2385792732239\n",
      "Solver termination condition: feasible\n",
      "Valid Tree : Yes\n",
      "GLPSOL--GLPK LP/MIP Solver 5.0\n",
      "Parameter(s) specified in the command line:\n",
      " --tmlim 600 --mipgap 0.05 --fpump --bestb --write /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmplqicwkj2.glpk.raw\n",
      " --wglp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpw8rgtqzu.glpk.glp\n",
      " --cpxlp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiesdkorv.pyomo.lp\n",
      "Reading problem data from '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiesdkorv.pyomo.lp'...\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiesdkorv.pyomo.lp:424982: warning: lower bound of variable 'x11' redefined\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiesdkorv.pyomo.lp:424982: warning: upper bound of variable 'x11' redefined\n",
      "21506 rows, 6608 columns, 353831 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "425101 lines were read\n",
      "Writing problem data to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpw8rgtqzu.glpk.glp'...\n",
      "409922 lines were written\n",
      "GLPK Integer Optimizer 5.0\n",
      "21506 rows, 6608 columns, 353831 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "19880 rows, 6607 columns, 352205 non-zeros\n",
      "119 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.240e+03  ratio =  1.240e+03\n",
      "GM: min|aij| =  1.921e-01  max|aij| =  5.207e+00  ratio =  2.711e+01\n",
      "EQ: min|aij| =  3.721e-02  max|aij| =  1.000e+00  ratio =  2.687e+01\n",
      "2N: min|aij| =  3.125e-02  max|aij| =  1.719e+00  ratio =  5.500e+01\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 19880\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "19880 rows, 6607 columns, 352205 non-zeros\n",
      "      0: obj =   5.000000000e-03 inf =   1.654e+02 (146)\n",
      "    231: obj =   4.538707865e+00 inf =   0.000e+00 (0) 1\n",
      "*   233: obj =   5.000000000e-03 inf =   0.000e+00 (0)\n",
      "OPTIMAL LP SOLUTION FOUND\n",
      "Integer optimization begins...\n",
      "Long-step dual simplex will be used\n",
      "+   233: mip =     not found yet >=              -inf        (1; 0)\n",
      "Applying FPUMP heuristic...\n",
      "Pass 1\n",
      "*  5646: obj =   1.057639187e+00 inf =   1.206e-04 (2643) 49\n",
      "*  7691: obj =   1.033572140e+00 inf =   1.845e-04 (2703) 18\n",
      "*  9977: obj =   1.020137622e+00 inf =   3.081e-04 (2861) 19\n",
      "* 12323: obj =   1.009022017e+00 inf =   3.841e-04 (1891) 19\n",
      "* 14601: obj =   9.999994465e-01 inf =   4.858e-04 (807) 20\n",
      "* 15419: obj =   1.000000000e+00 inf =   5.721e-15 (0) 7\n",
      "Pass 2\n",
      "* 23636: obj =   2.360526526e+01 inf =   3.749e-04 (2970) 29\n",
      "* 25594: obj =   2.262028881e+01 inf =   4.049e-04 (3004) 15\n",
      "* 27680: obj =   2.223988593e+01 inf =   3.293e-04 (2399) 18\n",
      "* 30035: obj =   2.002862703e+01 inf =   9.402e-05 (1882) 20\n",
      "* 32748: obj =   1.692605905e+01 inf =   5.993e-05 (1319) 22\n",
      "* 35340: obj =   1.676886368e+01 inf =   7.520e-16 (0) 21\n",
      "* 40981: obj =   2.300860770e+00 inf =   1.815e-05 (751) 49\n",
      "* 41184: obj =   2.298398001e+00 inf =   3.619e-13 (0) 1\n",
      "* 50240: obj =   1.168633845e+00 inf =   1.963e-16 (1051) 44\n",
      "* 52871: obj =   1.053082862e+00 inf =   2.025e-15 (2741) 22\n",
      "* 53822: obj =   1.046212491e+00 inf =   1.242e-15 (0) 8\n",
      "* 64615: obj =   1.503703043e+00 inf =   4.221e-05 (826) 46\n",
      "* 66830: obj =   1.384855234e+00 inf =   3.943e-05 (2453) 21\n",
      "* 67710: obj =   1.372630739e+00 inf =   5.849e-15 (0) 8\n",
      "* 72042: obj =   1.517601564e+00 inf =   5.501e-05 (398) 39\n",
      "* 72305: obj =   1.514649213e+00 inf =   3.469e-16 (0) 3\n",
      "* 80459: obj =   8.989916722e-01 inf =   2.754e-05 (2975) 48\n",
      "* 81077: obj =   8.873435735e-01 inf =   1.471e-15 (0) 5\n",
      "Pass 3\n",
      "* 97470: obj =   1.795717331e+01 inf =   1.792e-05 (1538) 41\n",
      "* 99581: obj =   1.401928375e+01 inf =   1.136e-14 (0) 15\n",
      "Pass 4\n",
      "Pass 5\n",
      "+   233: mip =     not found yet >=   5.000000000e-03        (2; 0)\n",
      "Time used: 245.5 secs.  Memory used: 53.6 Mb.\n",
      "#  6797: obj =   5.101071685e-03 inf =   0.000e+00 (4196) 50 96%\n",
      "#  9472: obj =   5.253799756e-03 inf =   0.000e+00 (3213) 24 98%\n",
      "# 11808: obj =   5.773726950e-03 inf =   0.000e+00 (5384) 21 98%\n",
      "# 14080: obj =   6.669461987e-03 inf =   0.000e+00 (1522) 20 99%\n",
      "# 16164: obj =   7.503242326e-03 inf =   0.000e+00 (2061) 18 99%\n",
      "# 17517: obj =   7.500000000e-03 inf =   0.000e+00 (0) 13 100%\n",
      "+ 17517: mip =     not found yet >=   5.000000000e-03        (8; 0)\n",
      "# 22103: obj =   1.014343789e-02 inf =   0.000e+00 (4038) 35 95%\n",
      "# 24143: obj =   1.080039843e-02 inf =   0.000e+00 (2871) 18 99%\n",
      "# 25592: obj =   1.166666667e-02 inf =   0.000e+00 (0) 12 99%\n",
      "+ 25592: mip =     not found yet >=   5.000000000e-03        (10; 0)\n",
      "# 33850: obj =   5.094298924e-03 inf =   0.000e+00 (2723) 51 96%\n",
      "# 36519: obj =   5.142317384e-03 inf =   0.000e+00 (5529) 23 99%\n",
      "# 38839: obj =   5.250497679e-03 inf =   0.000e+00 (3161) 20 99%\n",
      "# 40755: obj =   5.328177403e-03 inf =   0.000e+00 (4937) 17 99%\n",
      "# 42441: obj =   5.698547284e-03 inf =   0.000e+00 (5360) 16 98%\n",
      "# 43913: obj =   5.886501680e-03 inf =   0.000e+00 (4308) 12 100%\n",
      "# 45849: obj =   6.115918401e-03 inf =   0.000e+00 (2400) 16 99%\n",
      "# 47658: obj =   6.518128073e-03 inf =   0.000e+00 (2201) 17 99%\n",
      "# 49591: obj =   7.370816502e-03 inf =   0.000e+00 (2356) 17 99%\n",
      "# 51829: obj =   7.409767426e-03 inf =   0.000e+00 (2905) 21 99%\n",
      "# 54170: obj =   7.442348389e-03 inf =   0.000e+00 (3070) 22 99%\n",
      "# 54735: obj =   7.445652174e-03 inf =   0.000e+00 (0) 5 100%\n",
      "+ 54735: mip =     not found yet >=   5.000000000e-03        (11; 1)\n",
      "Time used: 362.6 secs.  Memory used: 61.1 Mb.\n",
      "+ 58281: mip =     not found yet >=   5.000000000e-03        (12; 1)\n",
      "# 65086: obj =   5.370919021e-03 inf =   0.000e+00 (4030) 58 94%\n",
      "# 67165: obj =   6.009653455e-03 inf =   0.000e+00 (5079) 19 98%\n",
      "# 69144: obj =   6.375549362e-03 inf =   0.000e+00 (3619) 17 99%\n",
      "# 71531: obj =   6.941025158e-03 inf =   0.000e+00 (2569) 22 99%\n",
      "# 73354: obj =   7.500000000e-03 inf =   9.814e-15 (0) 17 99%\n",
      "+ 73354: mip =     not found yet >=   5.000000000e-03        (14; 2)\n",
      "+ 79827: mip =     not found yet >=   5.000000000e-03        (16; 2)\n",
      "# 87332: obj =   5.229855424e-03 inf =   0.000e+00 (3009) 55 96%\n",
      "# 89896: obj =   5.413057972e-03 inf =   0.000e+00 (4542) 23 99%\n",
      "# 92195: obj =   6.112785435e-03 inf =   0.000e+00 (2976) 20 99%\n",
      "# 94423: obj =   6.511782132e-03 inf =   0.000e+00 (4194) 21 99%\n",
      "# 96213: obj =   6.747598546e-03 inf =   0.000e+00 (3042) 15 99%\n",
      "# 98040: obj =   7.205523180e-03 inf =   0.000e+00 (2010) 17 99%\n",
      "# 99826: obj =   7.274882547e-03 inf =   0.000e+00 (1671) 16 99%\n",
      "#101551: obj =   7.301415276e-03 inf =   0.000e+00 (2255) 16 99%\n",
      "#103458: obj =   7.336794831e-03 inf =   0.000e+00 (1072) 17 99%\n",
      "#105274: obj =   7.410752789e-03 inf =   0.000e+00 (2280) 18 100%\n",
      "#106948: obj =   7.445280518e-03 inf =   0.000e+00 (1925) 16 100%\n",
      "#107813: obj =   7.445652174e-03 inf =   0.000e+00 (0) 8 99%\n",
      "+107813: mip =     not found yet >=   5.000000000e-03        (16; 3)\n",
      "Time used: 472.3 secs.  Memory used: 62.0 Mb.\n",
      "#112139: obj =   5.013955413e-03 inf =   0.000e+00 (2886) 28 85%\n",
      "#113521: obj =   5.018337375e-03 inf =   0.000e+00 (2435) 13 93%\n",
      "#114688: obj =   5.025161159e-03 inf =   0.000e+00 (3067) 11 99%\n",
      "#115342: obj =   5.025907892e-03 inf =   0.000e+00 (3478) 6 100%\n",
      "#116231: obj =   5.033633551e-03 inf =   0.000e+00 (3424) 8 99%\n",
      "#117215: obj =   5.039909995e-03 inf =   0.000e+00 (3345) 9 99%\n",
      "#118299: obj =   5.063382083e-03 inf =   0.000e+00 (4980) 10 99%\n",
      "#119762: obj =   5.091638970e-03 inf =   0.000e+00 (4537) 14 98%\n"
     ]
    }
   ],
   "source": [
    "# Run the GA\n",
    "logmodel = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"glpk\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'fp_heur': fp_heur,\n",
    "                                                  'backtrack': backtrack\n",
    "                                                  }\n",
    "                                  )\n",
    "# X_train,X_test, Y_train, Y_test = split(X, y)\n",
    "chromo_df_bc,score_bc=generations(select_X_train,y_train,size=807,n_feat=select_X_train.shape[1],n_parents=8,mutation_rate=0.20,n_gen=2,\n",
    "                         X_train = select_X_train,X_test = select_X_train,Y_train = y_train,Y_test = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "(807, 35)\n",
      "(807, 47)\n",
      "(807,)\n"
     ]
    }
   ],
   "source": [
    "# Select the features indicated by the GA\n",
    "print(chromo_df_bc)\n",
    "print(names)\n",
    "# names = []\n",
    "# select_X_train = []\n",
    "# for i in range(len(chromo_df_bc[2])):\n",
    "#     if chromo_df_bc[2][i] == True:\n",
    "#         names.append(fraud_data.iloc[:, [i]].columns[0])\n",
    "#         select_X_train.append(X_train[:, i])\n",
    "# select_X_train = np.asarray(select_X_train).T\n",
    "# print(len(names))\n",
    "# print(select_X_train.shape)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "# selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "# select_X_train = selection.transform(X_train)\n",
    "\n",
    "# OCT parameters\n",
    "max_depth = 5\n",
    "min_samples_leaf = 1\n",
    "alpha = 0.01\n",
    "time_limit = 60  # minute\n",
    "mip_gap_tol = 0.05  # optimal gap percentage\n",
    "mip_focus = 'balance'\n",
    "mip_polish_time = None\n",
    "fp_heur = True\n",
    "backtrack = \"bestb\"\n",
    "\n",
    "warm_start = False\n",
    "log_file = None\n",
    "\n",
    "# Construct BNP-OCT classifier\n",
    "selection_model = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"glpk\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': \"all\",\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'fp_heur': True,\n",
    "                                                  'backtrack': backtrack\n",
    "                                                  }\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLPSOL--GLPK LP/MIP Solver 5.0\n",
      "Parameter(s) specified in the command line:\n",
      " --tmlim 900 --cuts --mipgap 0.05 --fpump --bestb --write /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpzs667ute.glpk.raw\n",
      " --wglp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpin0_tvmx.glpk.glp\n",
      " --cpxlp /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiifcxh_h.pyomo.lp\n",
      "Reading problem data from '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiifcxh_h.pyomo.lp'...\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiifcxh_h.pyomo.lp:18908370: warning: lower bound of variable 'x35' redefined\n",
      "/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpiifcxh_h.pyomo.lp:18908370: warning: upper bound of variable 'x35' redefined\n",
      "729050 rows, 27410 columns, 16693737 non-zeros\n",
      "1457 integer variables, all of which are binary\n",
      "18909827 lines were read\n",
      "Writing problem data to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpin0_tvmx.glpk.glp'...\n",
      "18205110 lines were written\n",
      "GLPK Integer Optimizer 5.0\n",
      "729050 rows, 27410 columns, 16693737 non-zeros\n",
      "1457 integer variables, all of which are binary\n",
      "Preprocessing...\n",
      "727424 rows, 27409 columns, 16692111 non-zeros\n",
      "1457 integer variables, all of which are binary\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.408e+03  ratio =  1.408e+03\n",
      "GM: min|aij| =  1.872e-01  max|aij| =  5.341e+00  ratio =  2.853e+01\n",
      "EQ: min|aij| =  3.570e-02  max|aij| =  1.000e+00  ratio =  2.802e+01\n",
      "2N: min|aij| =  3.125e-02  max|aij| =  1.688e+00  ratio =  5.400e+01\n",
      "Constructing initial basis...\n",
      "Size of triangular part is 727424\n",
      "Solving LP relaxation...\n",
      "GLPK Simplex Optimizer 5.0\n",
      "727424 rows, 27409 columns, 16692111 non-zeros\n",
      "      0: obj =   1.000000000e-02 inf =   1.406e+02 (132)\n",
      "Perturbing LP to avoid stalling [215]...\n",
      "    246: obj =   2.898734177e-02 inf =   8.363e+01 (130) 1\n",
      "    446: obj =   2.898734177e-02 inf =   8.363e+01 (130) 2\n",
      "    632: obj =   2.898734177e-02 inf =   8.363e+01 (130) 2\n",
      "    803: obj =   2.898734177e-02 inf =   8.363e+01 (130) 2\n",
      "    954: obj =   2.898734177e-02 inf =   8.363e+01 (130) 1\n",
      "   1063: obj =   2.898734177e-02 inf =   8.363e+01 (130) 1\n",
      "   1163: obj =   2.898734177e-02 inf =   8.363e+01 (130) 1\n",
      "   1252: obj =   2.898735478e-02 inf =   8.363e+01 (130) 1\n",
      "   1346: obj =   2.898736508e-02 inf =   8.363e+01 (130) 1\n",
      "   1451: obj =   2.898738065e-02 inf =   8.363e+01 (130) 1\n",
      "   1583: obj =   2.898739639e-02 inf =   8.363e+01 (130) 1\n",
      "   1716: obj =   2.898746138e-02 inf =   8.363e+01 (130) 1\n",
      "   1842: obj =   2.898759714e-02 inf =   8.363e+01 (130) 2\n",
      "   1954: obj =   2.898769188e-02 inf =   8.363e+01 (130) 1\n",
      "   2054: obj =   2.898774274e-02 inf =   8.363e+01 (130) 1\n",
      "   2148: obj =   2.898780570e-02 inf =   8.363e+01 (130) 1\n",
      "   2249: obj =   2.898783939e-02 inf =   8.363e+01 (130) 1\n",
      "   2356: obj =   2.898796844e-02 inf =   8.362e+01 (130) 1\n",
      "   2462: obj =   2.898802936e-02 inf =   8.362e+01 (130) 1\n",
      "   2557: obj =   4.691877746e-02 inf =   4.194e+01 (66) 1\n",
      "   2661: obj =   6.063338530e-02 inf =   2.951e+01 (11) 1\n",
      "   2776: obj =   6.063352793e-02 inf =   2.951e+01 (11) 1\n",
      "   2890: obj =   6.063366065e-02 inf =   2.951e+01 (11) 1\n",
      "   3008: obj =   6.063371484e-02 inf =   2.951e+01 (11) 1\n",
      "   3104: obj =   6.063380719e-02 inf =   2.951e+01 (11) 1\n",
      "   3207: obj =   6.063383515e-02 inf =   2.951e+01 (11) 1\n",
      "   3294: obj =   6.063398064e-02 inf =   2.951e+01 (11) 1\n",
      "   3383: obj =   7.329207352e-02 inf =   2.633e+01 (11) 1\n",
      "   3480: obj =   7.329220087e-02 inf =   2.633e+01 (11) 1\n",
      "   3578: obj =   7.329229975e-02 inf =   2.633e+01 (11) 1\n",
      "   3681: obj =   7.329233901e-02 inf =   2.633e+01 (11) 1\n",
      "   3786: obj =   7.329242925e-02 inf =   2.633e+01 (11) 1\n",
      "   3888: obj =   8.319614465e-02 inf =   2.382e+01 (8) 1\n",
      "   3998: obj =   8.594966219e-02 inf =   2.359e+01 (3) 1\n",
      "   4089: obj =   8.594974847e-02 inf =   2.359e+01 (3)\n",
      "   4168: obj =   8.594981345e-02 inf =   2.359e+01 (3) 1\n",
      "   4262: obj =   8.594985399e-02 inf =   2.359e+01 (3) 1\n",
      "   4329: obj =   8.594993641e-02 inf =   2.359e+01 (3) 1\n",
      "   4413: obj =   8.595006268e-02 inf =   2.359e+01 (3) 1\n",
      "   4514: obj =   8.595014560e-02 inf =   2.359e+01 (3) 1\n",
      "   4625: obj =   8.595037985e-02 inf =   2.359e+01 (3) 1\n",
      "   4731: obj =   8.595049791e-02 inf =   2.359e+01 (3) 1\n",
      "   4837: obj =   8.595071107e-02 inf =   2.359e+01 (3) 1\n",
      "   4938: obj =   8.595080533e-02 inf =   2.359e+01 (3) 1\n",
      "   5033: obj =   8.595103959e-02 inf =   2.359e+01 (3)\n",
      "   5118: obj =   8.595123852e-02 inf =   2.359e+01 (3) 1\n",
      "   5205: obj =   8.595130856e-02 inf =   2.359e+01 (3) 1\n",
      "   5295: obj =   8.595165628e-02 inf =   2.359e+01 (3) 1\n",
      "   5388: obj =   9.228080273e-02 inf =   2.343e+01 (3) 1\n",
      "   5488: obj =   9.228081968e-02 inf =   2.343e+01 (3) 1\n",
      "   5585: obj =   9.228096059e-02 inf =   2.343e+01 (3) 1\n",
      "   5681: obj =   9.228112190e-02 inf =   2.343e+01 (3) 1\n",
      "   5782: obj =   9.228129559e-02 inf =   2.343e+01 (3) 1\n",
      "   5879: obj =   9.228158206e-02 inf =   2.343e+01 (3)\n",
      "   5978: obj =   9.228174671e-02 inf =   2.343e+01 (3) 1\n",
      "   6067: obj =   9.228210197e-02 inf =   2.343e+01 (3) 1\n",
      "   6173: obj =   9.228240257e-02 inf =   2.343e+01 (3) 1\n",
      "   6286: obj =   9.228284800e-02 inf =   2.343e+01 (3) 1\n",
      "   6406: obj =   9.228293872e-02 inf =   2.343e+01 (3) 1\n",
      "   6509: obj =   9.228350958e-02 inf =   2.343e+01 (3) 1\n",
      "   6599: obj =   9.861291054e-02 inf =   2.328e+01 (3) 1\n",
      "   6680: obj =   9.861320028e-02 inf =   2.328e+01 (3) 1\n",
      "   6766: obj =   9.861357008e-02 inf =   2.328e+01 (3) 1\n",
      "   6848: obj =   9.861400225e-02 inf =   2.328e+01 (3)\n",
      "   6922: obj =   9.861432839e-02 inf =   2.328e+01 (3) 1\n",
      "   7011: obj =   9.861457876e-02 inf =   2.328e+01 (3) 1\n",
      "   7109: obj =   9.861527849e-02 inf =   2.328e+01 (3) 1\n",
      "   7225: obj =   9.861587297e-02 inf =   2.328e+01 (3) 1\n",
      "   7353: obj =   9.861633435e-02 inf =   2.328e+01 (3) 1\n",
      "   7479: obj =   9.861674570e-02 inf =   2.328e+01 (3) 1\n",
      "   7601: obj =   9.861768796e-02 inf =   2.328e+01 (3) 1\n",
      "   7712: obj =   9.861829630e-02 inf =   2.328e+01 (3) 1\n",
      "   7817: obj =   9.861898791e-02 inf =   2.328e+01 (3) 1\n",
      "   7914: obj =   9.861940836e-02 inf =   2.328e+01 (3) 1\n",
      "   7997: obj =   9.861998839e-02 inf =   2.328e+01 (3) 1\n",
      "   8095: obj =   9.862022129e-02 inf =   2.328e+01 (3)\n",
      "   8186: obj =   9.862054387e-02 inf =   2.328e+01 (3) 1\n",
      "   8281: obj =   9.862085133e-02 inf =   2.328e+01 (3) 1\n",
      "   8381: obj =   9.862105379e-02 inf =   2.328e+01 (3) 1\n",
      "   8487: obj =   9.862146374e-02 inf =   2.328e+01 (3) 1\n",
      "   8597: obj =   9.862225736e-02 inf =   2.328e+01 (3) 1\n",
      "   8711: obj =   9.862318683e-02 inf =   2.328e+01 (3) 1\n",
      "   8823: obj =   9.862386362e-02 inf =   2.328e+01 (3) 1\n",
      "   8927: obj =   9.862431141e-02 inf =   2.328e+01 (3) 1\n",
      "   9013: obj =   9.862516902e-02 inf =   2.328e+01 (3) 1\n",
      "   9097: obj =   9.862556251e-02 inf =   2.328e+01 (3) 1\n",
      "   9180: obj =   9.862605238e-02 inf =   2.328e+01 (3)\n",
      "   9258: obj =   9.862637410e-02 inf =   2.328e+01 (3) 1\n",
      "   9336: obj =   9.862687416e-02 inf =   2.328e+01 (3)\n",
      "   9417: obj =   9.862727567e-02 inf =   2.328e+01 (3) 1\n",
      "   9500: obj =   9.862782064e-02 inf =   2.328e+01 (3) 1\n",
      "   9593: obj =   9.862812575e-02 inf =   2.328e+01 (3) 1\n",
      "   9691: obj =   9.862896843e-02 inf =   2.328e+01 (3) 1\n",
      "   9805: obj =   9.863003690e-02 inf =   2.328e+01 (3)\n",
      "   9910: obj =   9.863076110e-02 inf =   2.328e+01 (3) 1\n",
      "  10004: obj =   9.863100905e-02 inf =   2.328e+01 (3) 1\n",
      "  10079: obj =   9.863223135e-02 inf =   2.328e+01 (3) 1\n",
      "  10149: obj =   9.863264138e-02 inf =   2.328e+01 (3) 1\n",
      "  10218: obj =   9.863289095e-02 inf =   2.328e+01 (3)\n",
      "  10257: obj =   9.863311825e-02 inf =   2.328e+01 (3) 1\n",
      "  10286: obj =   9.863316223e-02 inf =   2.328e+01 (3)\n",
      "  10306: obj =   9.863342116e-02 inf =   2.328e+01 (3)\n",
      "  10337: obj =   9.863392506e-02 inf =   2.328e+01 (3)\n",
      "  10382: obj =   9.863421320e-02 inf =   2.328e+01 (3) 1\n",
      "  10472: obj =   9.863455179e-02 inf =   2.328e+01 (3)\n",
      "  10586: obj =   9.863494657e-02 inf =   2.328e+01 (3) 1\n",
      "  10714: obj =   9.863588914e-02 inf =   2.328e+01 (3) 2\n",
      "  10845: obj =   9.863729798e-02 inf =   2.328e+01 (3) 1\n",
      "  10982: obj =   9.863808439e-02 inf =   2.328e+01 (3) 1\n",
      "  11107: obj =   9.863904282e-02 inf =   2.328e+01 (3) 1\n",
      "  11221: obj =   9.863997792e-02 inf =   2.328e+01 (3) 1\n",
      "  11316: obj =   9.864027885e-02 inf =   2.328e+01 (3) 1\n",
      "  11389: obj =   9.864092202e-02 inf =   2.328e+01 (3) 1\n",
      "  11470: obj =   9.864158673e-02 inf =   2.328e+01 (3)\n",
      "  11540: obj =   9.864192280e-02 inf =   2.328e+01 (3) 1\n",
      "  11628: obj =   9.864221089e-02 inf =   2.328e+01 (3)\n",
      "  11709: obj =   9.864290098e-02 inf =   2.328e+01 (3) 1\n",
      "  11800: obj =   9.864354460e-02 inf =   2.328e+01 (3) 1\n",
      "  11878: obj =   9.864411890e-02 inf =   2.328e+01 (3)\n",
      "  11952: obj =   9.864423515e-02 inf =   2.328e+01 (3) 1\n",
      "  12037: obj =   9.864466361e-02 inf =   2.328e+01 (3)\n",
      "  12088: obj =   9.864470421e-02 inf =   2.328e+01 (3) 1\n",
      "  12154: obj =   9.864514648e-02 inf =   2.328e+01 (3)\n",
      "  12228: obj =   9.864568838e-02 inf =   2.328e+01 (3) 1\n",
      "  12309: obj =   9.864670478e-02 inf =   2.328e+01 (3) 1\n",
      "  12414: obj =   9.864700284e-02 inf =   2.328e+01 (3) 1\n",
      "  12543: obj =   9.864742362e-02 inf =   2.328e+01 (3)\n",
      "  12650: obj =   9.864791699e-02 inf =   2.328e+01 (3) 1\n",
      "  12758: obj =   9.864868083e-02 inf =   2.328e+01 (3) 1\n",
      "  12852: obj =   9.864943681e-02 inf =   2.328e+01 (3) 1\n",
      "  12938: obj =   9.865009603e-02 inf =   2.328e+01 (3) 1\n",
      "  13029: obj =   9.865085415e-02 inf =   2.328e+01 (3)\n",
      "  13105: obj =   9.865111826e-02 inf =   2.328e+01 (3) 1\n",
      "  13189: obj =   9.865129801e-02 inf =   2.328e+01 (3) 1\n",
      "  13275: obj =   9.865153749e-02 inf =   2.328e+01 (3) 1\n",
      "  13367: obj =   9.865196374e-02 inf =   2.328e+01 (3)\n",
      "  13418: obj =   9.865224550e-02 inf =   2.328e+01 (3) 1\n",
      "  13492: obj =   9.865274830e-02 inf =   2.328e+01 (3) 1\n",
      "  13571: obj =   9.865326509e-02 inf =   2.328e+01 (3)\n",
      "  13651: obj =   9.865387073e-02 inf =   2.328e+01 (3) 1\n",
      "  13759: obj =   9.865417344e-02 inf =   2.328e+01 (3) 1\n",
      "  13877: obj =   9.865524065e-02 inf =   2.328e+01 (3) 1\n",
      "  14000: obj =   9.865634238e-02 inf =   2.328e+01 (3) 1\n",
      "  14098: obj =   9.865696978e-02 inf =   2.328e+01 (3) 1\n",
      "  14163: obj =   9.865778279e-02 inf =   2.328e+01 (3) 1\n",
      "  14210: obj =   9.865796604e-02 inf =   2.328e+01 (3)\n",
      "  14233: obj =   9.865796604e-02 inf =   2.328e+01 (3)\n",
      "  14234: obj =   9.865796604e-02 inf =   2.328e+01 (3)\n",
      "  14239: obj =   9.865796604e-02 inf =   2.328e+01 (3)\n",
      "  14280: obj =   9.865812501e-02 inf =   2.328e+01 (3)\n",
      "  14312: obj =   9.865845042e-02 inf =   2.328e+01 (3) 1\n",
      "  14401: obj =   9.865935305e-02 inf =   2.328e+01 (3)\n",
      "  14492: obj =   9.866007801e-02 inf =   2.328e+01 (3) 1\n",
      "  14598: obj =   9.866121764e-02 inf =   2.328e+01 (3) 1\n",
      "  14706: obj =   9.866239811e-02 inf =   2.328e+01 (3) 1\n",
      "  14836: obj =   9.866279341e-02 inf =   2.328e+01 (3) 1\n",
      "  14940: obj =   9.866441847e-02 inf =   2.328e+01 (3)\n",
      "  15051: obj =   9.866493427e-02 inf =   2.328e+01 (3) 1\n",
      "  15166: obj =   9.866576685e-02 inf =   2.328e+01 (3) 1\n",
      "  15299: obj =   9.866618390e-02 inf =   2.328e+01 (3) 1\n",
      "  15425: obj =   9.866689599e-02 inf =   2.328e+01 (3) 1\n",
      "  15544: obj =   9.866815686e-02 inf =   2.328e+01 (3) 1\n",
      "  15663: obj =   9.866865269e-02 inf =   2.328e+01 (3) 1\n",
      "  15766: obj =   9.866956619e-02 inf =   2.328e+01 (3) 1\n",
      "  15870: obj =   9.867005132e-02 inf =   2.328e+01 (3) 1\n",
      "  15968: obj =   9.867110825e-02 inf =   2.328e+01 (3) 1\n",
      "  16065: obj =   9.867186435e-02 inf =   2.328e+01 (3)\n",
      "  16154: obj =   9.867264064e-02 inf =   2.328e+01 (3) 1\n",
      "  16235: obj =   9.867340619e-02 inf =   2.328e+01 (3) 1\n",
      "  16341: obj =   9.867369693e-02 inf =   2.328e+01 (3) 1\n",
      "  16457: obj =   9.867510734e-02 inf =   2.328e+01 (3)\n",
      "  16572: obj =   9.867595665e-02 inf =   2.328e+01 (3) 1\n",
      "  16679: obj =   9.867703237e-02 inf =   2.328e+01 (3) 2\n",
      "  16804: obj =   9.867880176e-02 inf =   2.328e+01 (3) 1\n",
      "  16916: obj =   9.868032660e-02 inf =   2.328e+01 (3)\n",
      "  17016: obj =   9.868222366e-02 inf =   2.328e+01 (3) 1\n",
      "  17111: obj =   9.868344499e-02 inf =   2.328e+01 (3) 1\n",
      "Removing LP perturbation [17203]...\n",
      "  17203: obj =   9.860759494e-02 inf =   2.328e+01 (3)\n",
      "TIME LIMIT EXCEEDED; SEARCH TERMINATED\n",
      "Time used:   930.8 secs\n",
      "Memory used: 2960.7 Mb (3104519972 bytes)\n",
      "Writing MIP solution to '/var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpzs667ute.glpk.raw'...\n",
      "756469 lines were written\n",
      "Solver running time: 950.2706348896027\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "type NoneType doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/arman/Documents/Arman/JHU/Assurance/optimaltree-master_1/XGBoost_and_GA.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/arman/Documents/Arman/JHU/Assurance/optimaltree-master_1/XGBoost_and_GA.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run BNP-OCT\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/arman/Documents/Arman/JHU/Assurance/optimaltree-master_1/XGBoost_and_GA.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m selection_model\u001b[39m.\u001b[39;49mfit(select_X_train, Y_train)\n",
      "File \u001b[0;32m~/Documents/Arman/JHU/Assurance/optimaltree-master_1/lsopt/tree.py:822\u001b[0m, in \u001b[0;36mBinNodePenaltyOptimalTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39m# Construct ModelTree object\u001b[39;00m\n\u001b[1;32m    815\u001b[0m tree_ \u001b[39m=\u001b[39m ModelBinTree(model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m    816\u001b[0m                      scaler_X\u001b[39m=\u001b[39mscaler_X,\n\u001b[1;32m    817\u001b[0m                      feature_removed_idx\u001b[39m=\u001b[39mfeature_removed_idx,\n\u001b[1;32m    818\u001b[0m                      classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_,\n\u001b[1;32m    819\u001b[0m                      criterion\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion,\n\u001b[1;32m    820\u001b[0m                      nodes_fashion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdfs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 822\u001b[0m tree_\u001b[39m.\u001b[39;49mshape(X_transformed\u001b[39m=\u001b[39;49mX_transformed,\n\u001b[1;32m    823\u001b[0m             y_transformed\u001b[39m=\u001b[39;49my_transformed,\n\u001b[1;32m    824\u001b[0m             feature_thresholds\u001b[39m=\u001b[39;49mfeature_thresholds\n\u001b[1;32m    825\u001b[0m             )\n\u001b[1;32m    826\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_time \u001b[39m=\u001b[39m run_time\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolution_condition \u001b[39m=\u001b[39m solution_condition\n",
      "File \u001b[0;32m~/Documents/Arman/JHU/Assurance/optimaltree-master_1/lsopt/_base.py:4841\u001b[0m, in \u001b[0;36mModelBinTree.shape\u001b[0;34m(self, X_transformed, y_transformed, feature_thresholds)\u001b[0m\n\u001b[1;32m   4838\u001b[0m leaf_nodes_active \u001b[39m=\u001b[39m []\n\u001b[1;32m   4840\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m branch_nodes:\n\u001b[0;32m-> 4841\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mround\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49md[node]\u001b[39m.\u001b[39;49mvalue) \u001b[39m==\u001b[39m \u001b[39m1.0\u001b[39m:\n\u001b[1;32m   4842\u001b[0m         branch_nodes_active\u001b[39m.\u001b[39mappend(node)\n\u001b[1;32m   4844\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m leaf_nodes:\n",
      "\u001b[0;31mTypeError\u001b[0m: type NoneType doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "# Run BNP-OCT\n",
    "selection_model.fit(select_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[718   0]\n",
      " [ 89   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       718\n",
      "           1       0.00      0.00      0.00        89\n",
      "\n",
      "    accuracy                           0.89       807\n",
      "   macro avg       0.44      0.50      0.47       807\n",
      "weighted avg       0.79      0.89      0.84       807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'optimal_tree_fraud.png'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction\n",
    "selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "select_X_test = selection.transform(X_train)\n",
    "y_pred = selection_model.predict(X=select_X_train)\n",
    "y_pred_prob = selection_model.predict_proba(X=select_X_train)\n",
    "\n",
    "# Check confusion matrix\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_true=y_train,\n",
    "                       y_pred=y_pred))\n",
    "\n",
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=y_pred))\n",
    "\n",
    "# Plot Optimal Tree\n",
    "feature_names = names\n",
    "class_names = ['Not-Fraud', 'Fraud']\n",
    "\n",
    "dot_data = tree.export_graphviz(selection_model,\n",
    "                                out_file=None,\n",
    "                                feature_names=feature_names,\n",
    "                                class_names=class_names,\n",
    "                                label='all',\n",
    "                                impurity=True,\n",
    "                                node_ids=True,\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                leaves_parallel=True,\n",
    "                                special_characters=False)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = 'png'\n",
    "graph.render(filename='optimal_tree_fraud', directory='', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in y_pred:\n",
    "    if element == 1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lsopt.tree.BinNodePenaltyOptimalTreeClassifier object at 0x12ead3e90>\n"
     ]
    }
   ],
   "source": [
    "print(selection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('optimal_tree_fraud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'solve_oct_MILP_BIN.<locals>.obj_rule'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\sagata\\Assurance\\optimaltree-master\\boost.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(selection_model, file)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'solve_oct_MILP_BIN.<locals>.obj_rule'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model_pkl', 'wb') as file:\n",
    "    pickle.dump(selection_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
