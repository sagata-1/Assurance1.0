{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost and GA with GLPK\n",
    "This notebook contains the implementation of a Genetic Algorithm to carry out feature selection. This hasn't produced a reasonable result however (in fact, it can't find a tree), as it appears to have selected too many features for use with BNP-OCT (35 features currently)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "\n",
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "# from lsopt.tree import OldOptimalTreeClassifier ## OCT proposed by Bertsimas & Dunn\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import tree \n",
    "\n",
    "import graphviz\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phy_same</th>\n",
       "      <th>phy_count</th>\n",
       "      <th>period</th>\n",
       "      <th>periodadmt</th>\n",
       "      <th>age</th>\n",
       "      <th>alife</th>\n",
       "      <th>provider_InscClaimAmtReimbursed_mean</th>\n",
       "      <th>provider_DeductibleAmtPaid_mean</th>\n",
       "      <th>provider_NoOfMonths_PartACov_mean</th>\n",
       "      <th>provider_NoOfMonths_PartBCov_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>diag1_OPAnnualDeductibleAmt_mean</th>\n",
       "      <th>diag1_InscClaimAmtReimbursed_std</th>\n",
       "      <th>diag1_DeductibleAmtPaid_std</th>\n",
       "      <th>diag1_NoOfMonths_PartACov_std</th>\n",
       "      <th>diag1_NoOfMonths_PartBCov_std</th>\n",
       "      <th>diag1_IPAnnualReimbursementAmt_std</th>\n",
       "      <th>diag1_IPAnnualDeductibleAmt_std</th>\n",
       "      <th>diag1_OPAnnualReimbursementAmt_std</th>\n",
       "      <th>diag1_OPAnnualDeductibleAmt_std</th>\n",
       "      <th>PotentialFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.960000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.240000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4185.600000</td>\n",
       "      <td>213.600000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>543.045084</td>\n",
       "      <td>3482.066310</td>\n",
       "      <td>161.353027</td>\n",
       "      <td>0.569945</td>\n",
       "      <td>0.424192</td>\n",
       "      <td>12941.552350</td>\n",
       "      <td>1205.297144</td>\n",
       "      <td>2450.076771</td>\n",
       "      <td>661.506672</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.439394</td>\n",
       "      <td>1.530303</td>\n",
       "      <td>3.674242</td>\n",
       "      <td>2.424242</td>\n",
       "      <td>71.371212</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>4588.409091</td>\n",
       "      <td>502.166667</td>\n",
       "      <td>11.818182</td>\n",
       "      <td>11.871212</td>\n",
       "      <td>...</td>\n",
       "      <td>676.313985</td>\n",
       "      <td>4017.871066</td>\n",
       "      <td>260.257069</td>\n",
       "      <td>0.726572</td>\n",
       "      <td>0.653285</td>\n",
       "      <td>12620.604410</td>\n",
       "      <td>1226.306633</td>\n",
       "      <td>3369.338617</td>\n",
       "      <td>848.213675</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.818792</td>\n",
       "      <td>1.604027</td>\n",
       "      <td>1.429530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.516779</td>\n",
       "      <td>0.993289</td>\n",
       "      <td>350.134228</td>\n",
       "      <td>2.080537</td>\n",
       "      <td>11.865772</td>\n",
       "      <td>11.959732</td>\n",
       "      <td>...</td>\n",
       "      <td>694.246881</td>\n",
       "      <td>1536.290845</td>\n",
       "      <td>113.086257</td>\n",
       "      <td>0.667719</td>\n",
       "      <td>0.577420</td>\n",
       "      <td>11016.516940</td>\n",
       "      <td>1111.592405</td>\n",
       "      <td>2972.377916</td>\n",
       "      <td>808.138208</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.731330</td>\n",
       "      <td>1.599142</td>\n",
       "      <td>1.088412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.783691</td>\n",
       "      <td>0.996567</td>\n",
       "      <td>241.124463</td>\n",
       "      <td>3.175966</td>\n",
       "      <td>11.907296</td>\n",
       "      <td>11.939914</td>\n",
       "      <td>...</td>\n",
       "      <td>630.805985</td>\n",
       "      <td>1234.005090</td>\n",
       "      <td>91.141252</td>\n",
       "      <td>0.657071</td>\n",
       "      <td>0.565930</td>\n",
       "      <td>10021.329570</td>\n",
       "      <td>957.701391</td>\n",
       "      <td>2727.944083</td>\n",
       "      <td>737.419878</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.736111</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>70.583333</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>468.194444</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>11.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>606.550334</td>\n",
       "      <td>1519.425993</td>\n",
       "      <td>103.302166</td>\n",
       "      <td>0.626542</td>\n",
       "      <td>0.520122</td>\n",
       "      <td>10565.761430</td>\n",
       "      <td>1126.358206</td>\n",
       "      <td>2486.827069</td>\n",
       "      <td>682.279276</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>2.548387</td>\n",
       "      <td>1.548387</td>\n",
       "      <td>2.806452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.677419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>127.741935</td>\n",
       "      <td>1.612903</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>539.926413</td>\n",
       "      <td>1278.578369</td>\n",
       "      <td>105.316369</td>\n",
       "      <td>0.642724</td>\n",
       "      <td>0.506470</td>\n",
       "      <td>10069.067870</td>\n",
       "      <td>1048.496358</td>\n",
       "      <td>2331.087492</td>\n",
       "      <td>676.226785</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>544.784235</td>\n",
       "      <td>589.615472</td>\n",
       "      <td>61.510304</td>\n",
       "      <td>0.690826</td>\n",
       "      <td>0.473344</td>\n",
       "      <td>10885.075840</td>\n",
       "      <td>1026.840019</td>\n",
       "      <td>2547.341333</td>\n",
       "      <td>723.822292</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>613.157895</td>\n",
       "      <td>4778.012673</td>\n",
       "      <td>463.684066</td>\n",
       "      <td>0.600751</td>\n",
       "      <td>0.710275</td>\n",
       "      <td>13241.321690</td>\n",
       "      <td>1469.095843</td>\n",
       "      <td>3203.267596</td>\n",
       "      <td>911.406530</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>566.953462</td>\n",
       "      <td>2506.463260</td>\n",
       "      <td>131.832995</td>\n",
       "      <td>0.726815</td>\n",
       "      <td>0.354062</td>\n",
       "      <td>11262.841610</td>\n",
       "      <td>1196.045563</td>\n",
       "      <td>2691.729344</td>\n",
       "      <td>736.415563</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>2.634921</td>\n",
       "      <td>1.539683</td>\n",
       "      <td>1.349206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.873016</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>204.444444</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>11.809524</td>\n",
       "      <td>11.809524</td>\n",
       "      <td>...</td>\n",
       "      <td>587.854714</td>\n",
       "      <td>1114.462613</td>\n",
       "      <td>97.400585</td>\n",
       "      <td>0.599785</td>\n",
       "      <td>0.533154</td>\n",
       "      <td>9713.456656</td>\n",
       "      <td>1014.932899</td>\n",
       "      <td>2579.061940</td>\n",
       "      <td>707.121804</td>\n",
       "      <td>Not-Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      phy_same  phy_count    period  periodadmt        age     alife  \\\n",
       "0     2.960000   1.600000  1.440000    1.000000  80.240000  1.000000   \n",
       "1     2.439394   1.530303  3.674242    2.424242  71.371212  0.992424   \n",
       "2     2.818792   1.604027  1.429530    0.000000  73.516779  0.993289   \n",
       "3     2.731330   1.599142  1.088412    0.000000  71.783691  0.996567   \n",
       "4     2.736111   1.527778  0.958333    0.222222  70.583333  0.986111   \n",
       "...        ...        ...       ...         ...        ...       ...   \n",
       "1004  2.548387   1.548387  2.806452    0.000000  75.677419  1.000000   \n",
       "1005  2.500000   1.500000  0.100000    0.000000  78.000000  1.000000   \n",
       "1006  3.000000   2.000000  0.000000    0.000000  74.000000  1.000000   \n",
       "1007  2.333333   1.333333  2.266667    0.000000  73.933333  1.000000   \n",
       "1008  2.634921   1.539683  1.349206    0.000000  77.873016  0.984127   \n",
       "\n",
       "      provider_InscClaimAmtReimbursed_mean  provider_DeductibleAmtPaid_mean  \\\n",
       "0                              4185.600000                       213.600000   \n",
       "1                              4588.409091                       502.166667   \n",
       "2                               350.134228                         2.080537   \n",
       "3                               241.124463                         3.175966   \n",
       "4                               468.194444                        45.333333   \n",
       "...                                    ...                              ...   \n",
       "1004                            127.741935                         1.612903   \n",
       "1005                             72.000000                         0.000000   \n",
       "1006                             50.000000                         0.000000   \n",
       "1007                            296.000000                         0.000000   \n",
       "1008                            204.444444                         0.793651   \n",
       "\n",
       "      provider_NoOfMonths_PartACov_mean  provider_NoOfMonths_PartBCov_mean  \\\n",
       "0                             12.000000                          12.000000   \n",
       "1                             11.818182                          11.871212   \n",
       "2                             11.865772                          11.959732   \n",
       "3                             11.907296                          11.939914   \n",
       "4                             11.833333                          11.833333   \n",
       "...                                 ...                                ...   \n",
       "1004                          12.000000                          12.000000   \n",
       "1005                          12.000000                          12.000000   \n",
       "1006                          12.000000                          12.000000   \n",
       "1007                          12.000000                          12.000000   \n",
       "1008                          11.809524                          11.809524   \n",
       "\n",
       "      ...  diag1_OPAnnualDeductibleAmt_mean  diag1_InscClaimAmtReimbursed_std  \\\n",
       "0     ...                        543.045084                       3482.066310   \n",
       "1     ...                        676.313985                       4017.871066   \n",
       "2     ...                        694.246881                       1536.290845   \n",
       "3     ...                        630.805985                       1234.005090   \n",
       "4     ...                        606.550334                       1519.425993   \n",
       "...   ...                               ...                               ...   \n",
       "1004  ...                        539.926413                       1278.578369   \n",
       "1005  ...                        544.784235                        589.615472   \n",
       "1006  ...                        613.157895                       4778.012673   \n",
       "1007  ...                        566.953462                       2506.463260   \n",
       "1008  ...                        587.854714                       1114.462613   \n",
       "\n",
       "      diag1_DeductibleAmtPaid_std  diag1_NoOfMonths_PartACov_std  \\\n",
       "0                      161.353027                       0.569945   \n",
       "1                      260.257069                       0.726572   \n",
       "2                      113.086257                       0.667719   \n",
       "3                       91.141252                       0.657071   \n",
       "4                      103.302166                       0.626542   \n",
       "...                           ...                            ...   \n",
       "1004                   105.316369                       0.642724   \n",
       "1005                    61.510304                       0.690826   \n",
       "1006                   463.684066                       0.600751   \n",
       "1007                   131.832995                       0.726815   \n",
       "1008                    97.400585                       0.599785   \n",
       "\n",
       "      diag1_NoOfMonths_PartBCov_std  diag1_IPAnnualReimbursementAmt_std  \\\n",
       "0                          0.424192                        12941.552350   \n",
       "1                          0.653285                        12620.604410   \n",
       "2                          0.577420                        11016.516940   \n",
       "3                          0.565930                        10021.329570   \n",
       "4                          0.520122                        10565.761430   \n",
       "...                             ...                                 ...   \n",
       "1004                       0.506470                        10069.067870   \n",
       "1005                       0.473344                        10885.075840   \n",
       "1006                       0.710275                        13241.321690   \n",
       "1007                       0.354062                        11262.841610   \n",
       "1008                       0.533154                         9713.456656   \n",
       "\n",
       "      diag1_IPAnnualDeductibleAmt_std  diag1_OPAnnualReimbursementAmt_std  \\\n",
       "0                         1205.297144                         2450.076771   \n",
       "1                         1226.306633                         3369.338617   \n",
       "2                         1111.592405                         2972.377916   \n",
       "3                          957.701391                         2727.944083   \n",
       "4                         1126.358206                         2486.827069   \n",
       "...                               ...                                 ...   \n",
       "1004                      1048.496358                         2331.087492   \n",
       "1005                      1026.840019                         2547.341333   \n",
       "1006                      1469.095843                         3203.267596   \n",
       "1007                      1196.045563                         2691.729344   \n",
       "1008                      1014.932899                         2579.061940   \n",
       "\n",
       "      diag1_OPAnnualDeductibleAmt_std  PotentialFraud  \n",
       "0                          661.506672       Not-Fraud  \n",
       "1                          848.213675           Fraud  \n",
       "2                          808.138208       Not-Fraud  \n",
       "3                          737.419878           Fraud  \n",
       "4                          682.279276       Not-Fraud  \n",
       "...                               ...             ...  \n",
       "1004                       676.226785       Not-Fraud  \n",
       "1005                       723.822292       Not-Fraud  \n",
       "1006                       911.406530       Not-Fraud  \n",
       "1007                       736.415563       Not-Fraud  \n",
       "1008                       707.121804       Not-Fraud  \n",
       "\n",
       "[1009 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_fraud = './data/fraud_data_m_oct_ready.csv'\n",
    "fraud_data = pd.read_csv(data_path_fraud)\n",
    "fraud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fraud_data.iloc[:, 0:47].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fraud_data[\"PotentialFraud\"].apply(lambda val: 0 if val == \"Not-Fraud\" else 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.56%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]    \n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.000, n=47, Accuracy: 93.56%\n",
      "Thresh=0.005, n=41, Accuracy: 93.56%\n",
      "Thresh=0.009, n=40, Accuracy: 94.06%\n",
      "Thresh=0.009, n=39, Accuracy: 94.06%\n",
      "Thresh=0.009, n=38, Accuracy: 94.06%\n",
      "Thresh=0.010, n=37, Accuracy: 94.06%\n",
      "Thresh=0.011, n=36, Accuracy: 94.55%\n",
      "Thresh=0.011, n=35, Accuracy: 94.06%\n",
      "Thresh=0.011, n=34, Accuracy: 94.06%\n",
      "Thresh=0.012, n=33, Accuracy: 95.05%\n",
      "Thresh=0.012, n=32, Accuracy: 94.06%\n",
      "Thresh=0.012, n=31, Accuracy: 95.54%\n",
      "Thresh=0.012, n=30, Accuracy: 94.06%\n",
      "Thresh=0.013, n=29, Accuracy: 95.05%\n",
      "Thresh=0.013, n=28, Accuracy: 93.56%\n",
      "Thresh=0.014, n=27, Accuracy: 94.06%\n",
      "Thresh=0.014, n=26, Accuracy: 94.06%\n",
      "Thresh=0.014, n=25, Accuracy: 94.06%\n",
      "Thresh=0.015, n=24, Accuracy: 95.54%\n",
      "Thresh=0.015, n=23, Accuracy: 94.55%\n",
      "Thresh=0.016, n=22, Accuracy: 93.56%\n",
      "Thresh=0.017, n=21, Accuracy: 94.06%\n",
      "Thresh=0.017, n=20, Accuracy: 94.55%\n",
      "Thresh=0.020, n=19, Accuracy: 94.06%\n",
      "Thresh=0.020, n=18, Accuracy: 93.56%\n",
      "Thresh=0.020, n=17, Accuracy: 94.55%\n",
      "Thresh=0.022, n=16, Accuracy: 93.56%\n",
      "Thresh=0.023, n=15, Accuracy: 93.56%\n",
      "Thresh=0.024, n=14, Accuracy: 93.07%\n",
      "Thresh=0.025, n=13, Accuracy: 93.07%\n",
      "Thresh=0.025, n=12, Accuracy: 92.57%\n",
      "Thresh=0.026, n=11, Accuracy: 94.55%\n",
      "Thresh=0.026, n=10, Accuracy: 94.06%\n",
      "Thresh=0.029, n=9, Accuracy: 94.06%\n",
      "Thresh=0.030, n=8, Accuracy: 94.55%\n",
      "Thresh=0.032, n=7, Accuracy: 95.05%\n",
      "Thresh=0.045, n=6, Accuracy: 93.56%\n",
      "Thresh=0.046, n=5, Accuracy: 94.06%\n",
      "Thresh=0.047, n=4, Accuracy: 93.07%\n",
      "Thresh=0.063, n=3, Accuracy: 93.07%\n",
      "Thresh=0.080, n=2, Accuracy: 91.58%\n",
      "Thresh=0.127, n=1, Accuracy: 90.59%\n"
     ]
    }
   ],
   "source": [
    "thresholds = sort(model.feature_importances_)\n",
    "max_acc = -1\n",
    "true_thresh = -1\n",
    "for thresh in thresholds:\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train)\n",
    "    \n",
    "    selection_model = XGBClassifier()\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    \n",
    "    select_X_test = selection.transform(X_test)\n",
    "    y_pred = selection_model.predict(select_X_test)\n",
    "    \n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    if accuracy >= max_acc and select_X_train.shape[1] < 20:\n",
    "        max_acc = accuracy\n",
    "        true_thresh = thresh\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.032147862\n"
     ]
    }
   ],
   "source": [
    "print(true_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "select_X_train = selection.transform(X_train)\n",
    "\n",
    "# OCT parameters\n",
    "max_depth = 3\n",
    "min_samples_leaf = 7\n",
    "alpha = 0.005\n",
    "time_limit = 10 # minute\n",
    "mip_gap_tol = 0.05  # optimal gap percentage\n",
    "mip_focus = 'balance'\n",
    "mip_polish_time = None\n",
    "warm_start = False\n",
    "log_file = None\n",
    "fp_heur = True\n",
    "backtrack = \"bestb\"\n",
    "\n",
    "# Construct BNP-OCT classifier\n",
    "selection_model = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"gurobi\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': 'auto',\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'mip_focus': mip_focus,\n",
    "                                                  'mip_polish_time': mip_polish_time,\n",
    "                                                  }\n",
    "                                  )\n",
    "\n",
    "names = []\n",
    "for i in range(len(model.feature_importances_)):\n",
    "    if model.feature_importances_[i] >= true_thresh:\n",
    "        names.append(fraud_data.iloc[:, [i]].columns[0])\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of below code\n",
    "Alright, there's a few functions here, so lets go through them one by one.\n",
    "\n",
    "### Split\n",
    "This one is pretty straitforward, its the one that actually splits the data into a training set and a testing set\n",
    "\n",
    "### acc_score\n",
    "Returns the accuracy of each model\n",
    "\n",
    "### plot\n",
    "For plotting any results of the model, if I need to visualize it\n",
    "\n",
    "### initialization_of_population\n",
    "To initialize a random population.\n",
    "\n",
    "### fitness_score\n",
    "Returns the best parents for the next run, along with their fitness scores\n",
    "\n",
    "### selection\n",
    "Selects the best parents at the end of every run\n",
    "\n",
    "### crossover\n",
    "Picks half of the first parents, and half of the second\n",
    "\n",
    "### mutation\n",
    "Randomly flip the a feature from True to False (holding true to the principle of the genetic algorithm)\n",
    "\n",
    "### generations\n",
    "Executes all the above functions for the specified number of generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df,label):\n",
    "    selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "    X_tr = select_X_train\n",
    "    X_te = X_test\n",
    "    Y_tr = y_train\n",
    "    Y_te = y_test\n",
    "    return X_tr, X_te, Y_tr, Y_te\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "import random\n",
    "\n",
    "classifiers = ['LinearSVM', 'RadialSVM', \n",
    "               'Logistic',  'RandomForest', \n",
    "               'AdaBoost',  'DecisionTree', \n",
    "               'KNeighbors','GradientBoosting', 'BNP-OCT']\n",
    "\n",
    "models = [svm.SVC(kernel='linear'),\n",
    "          svm.SVC(kernel='rbf'),\n",
    "          LogisticRegression(max_iter = 1000),\n",
    "          RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "          AdaBoostClassifier(random_state = 0),\n",
    "          DecisionTreeClassifier(random_state=0),\n",
    "          KNeighborsClassifier(),\n",
    "          XGBClassifier(random_state=0),\n",
    "          BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"gurobi\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'mip_focus': mip_focus,\n",
    "                                                  'mip_polish_time': mip_polish_time,\n",
    "                                                  }\n",
    "                                  )]\n",
    "\n",
    "\n",
    "def acc_score(df,label):\n",
    "    Score = pd.DataFrame({\"Classifier\":classifiers})\n",
    "    j = 0\n",
    "    acc = []\n",
    "    X_train = select_X_train\n",
    "    X_test = select_X_train\n",
    "    Y_train = y_train\n",
    "    Y_test = y_train\n",
    "    for i in models:\n",
    "        model = i\n",
    "        model.fit(X_train,Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        acc.append(accuracy_score(Y_test,predictions))\n",
    "        j = j+1     \n",
    "    Score[\"Accuracy\"] = acc\n",
    "    Score.sort_values(by=\"Accuracy\", ascending=False,inplace = True)\n",
    "    Score.reset_index(drop=True, inplace=True)\n",
    "    return Score\n",
    "\n",
    "def plot(score,x,y,c = \"b\"):\n",
    "    gen = [1,2,3,4,5]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    ax = sns.pointplot(x=gen, y=score,color = c )\n",
    "    ax.set(xlabel=\"Generation\", ylabel=\"Accuracy\")\n",
    "    ax.set(ylim=(x,y))\n",
    "    \n",
    "def initilization_of_population(size,n_feat):\n",
    "    population = []\n",
    "    for i in range(size):\n",
    "        chromosome = np.ones(n_feat,dtype=bool)     \n",
    "        chromosome[:int(0.3*n_feat)]=False             \n",
    "        np.random.shuffle(chromosome)\n",
    "        population.append(chromosome)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_score(population):\n",
    "    scores = []\n",
    "    for chromosome in population:\n",
    "        logmodel.fit(select_X_train[:, chromosome],y_train)         \n",
    "        predictions = logmodel.predict(select_X_train[:, chromosome])\n",
    "        scores.append(accuracy_score(y_train,predictions))\n",
    "    scores, population = np.array(scores), np.array(population) \n",
    "    inds = np.argsort(scores)                                    \n",
    "    return list(scores[inds][::-1]), list(population[inds,:][::-1]) \n",
    "\n",
    "def selection(pop_after_fit,n_parents):\n",
    "    population_nextgen = []\n",
    "    for i in range(n_parents):\n",
    "        population_nextgen.append(pop_after_fit[i])\n",
    "    return population_nextgen\n",
    "\n",
    "\n",
    "def crossover(pop_after_sel):\n",
    "    pop_nextgen = pop_after_sel\n",
    "    for i in range(0,len(pop_after_sel),2):\n",
    "        new_par = []\n",
    "        child_1 , child_2 = pop_nextgen[i] , pop_nextgen[i+1]\n",
    "        new_par = np.concatenate((child_1[:len(child_1)//2],child_2[len(child_1)//2:]))\n",
    "        pop_nextgen.append(new_par)\n",
    "    return pop_nextgen\n",
    "\n",
    "def mutation(pop_after_cross,mutation_rate,n_feat):   \n",
    "    mutation_range = int(mutation_rate*n_feat)\n",
    "    pop_next_gen = []\n",
    "    for n in range(0,len(pop_after_cross)):\n",
    "        chromo = pop_after_cross[n]\n",
    "        rand_posi = [] \n",
    "        for i in range(0,mutation_range):\n",
    "            pos = random.randint(0,n_feat-1)\n",
    "            rand_posi.append(pos)\n",
    "        for j in rand_posi:\n",
    "            chromo[j] = not chromo[j]  \n",
    "        pop_next_gen.append(chromo)\n",
    "    return pop_next_gen\n",
    "\n",
    "def generations(df,label,size,n_feat,n_parents,mutation_rate,n_gen,X_train,\n",
    "                                   X_test, Y_train, Y_test):\n",
    "    best_chromo= []\n",
    "    best_score= []\n",
    "    population_nextgen=initilization_of_population(size,n_feat)\n",
    "    for i in range(n_gen):\n",
    "        scores, pop_after_fit = fitness_score(population_nextgen)\n",
    "        print('Best score in generation',i+1,':',scores[:1])  #2\n",
    "        pop_after_sel = selection(pop_after_fit,n_parents)\n",
    "        pop_after_cross = crossover(pop_after_sel)\n",
    "        population_nextgen = mutation(pop_after_cross,mutation_rate,n_feat)\n",
    "        best_chromo.append(pop_after_fit[0])\n",
    "        best_score.append(scores[0])\n",
    "    return best_chromo,best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of cell below\n",
    "The below cell essentially generates the accuracy of all the possible model classifiers that can be used (it appears that XGBoost is best, along with AdaBoost). Basically, what we're doing is running each model on the 7 features pre-selected with XGBoost, to determine which one runs in the most accurarte fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpmz6vog5g.pyomo.lp\n",
      "Reading time = 0.27 seconds\n",
      "x1: 26210 rows, 6622 columns, 438053 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 26210 rows, 6622 columns and 438053 nonzeros\n",
      "Model fingerprint: 0x13e0a78c\n",
      "Variable types: 6489 continuous, 133 integer (133 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 2026 rows and 451 columns\n",
      "Presolve time: 2.04s\n",
      "Presolved: 24184 rows, 6171 columns, 422661 nonzeros\n",
      "Variable types: 6044 continuous, 127 integer (127 binary)\n",
      "Found heuristic solution: objective 0.8327528\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    3963    5.0000000e-03   0.000000e+00   3.736446e-03      5s\n",
      "    3969    5.0000000e-03   0.000000e+00   0.000000e+00      5s\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 3969 iterations, 2.64 seconds (3.95 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    5    0.83275    0.00500  99.4%     -    5s\n",
      "H    0     0                       0.8215169    0.00500  99.4%     -    5s\n",
      "H    0     0                       0.7990449    0.00500  99.4%     -    6s\n",
      "     0     0    0.00500    0    4    0.79904    0.00500  99.4%     -   19s\n",
      "     0     0    0.00500    0    4    0.79904    0.00500  99.4%     -   21s\n",
      "     0     0    0.00500    0    6    0.79904    0.00500  99.4%     -   44s\n",
      "     0     0    0.00500    0    5    0.79904    0.00500  99.4%     -   50s\n",
      "     0     0    0.00500    0    4    0.79904    0.00500  99.4%     -   67s\n",
      "     0     0    0.00500    0    4    0.79904    0.00500  99.4%     -   77s\n",
      "     0     0    0.00500    0    5    0.79904    0.00500  99.4%     -  113s\n",
      "     0     0    0.00500    0    5    0.79904    0.00500  99.4%     -  137s\n",
      "     0     0    0.00500    0    5    0.79904    0.00500  99.4%     -  197s\n",
      "     0     0    0.00500    0    5    0.79904    0.00500  99.4%     -  198s\n",
      "     0     2    0.00500    0    5    0.79904    0.00500  99.4%     -  266s\n",
      "     1     4    0.00672    1   25    0.79904    0.00500  99.4% 47413  381s\n",
      "     3     8    0.00848    2   41    0.79904    0.00502  99.4% 31309  409s\n",
      "     7    12    0.02530    3   25    0.79904    0.00502  99.4% 16134  456s\n",
      "    11    14 infeasible    3         0.79904    0.00531  99.3% 13194  479s\n",
      "    15    18    0.04527    4   33    0.79904    0.00772  99.0% 11477  591s\n",
      "    19    20    0.00837    6    9    0.79904    0.00772  99.0% 11297  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 327\n",
      "  MIR: 122\n",
      "  Flow cover: 24\n",
      "  RLT: 15\n",
      "  Relax-and-lift: 260\n",
      "\n",
      "Explored 21 nodes (293980 simplex iterations) in 600.04 seconds (976.11 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0.799045 0.821517 0.832753 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 7.990449438202e-01, best bound 7.715206945214e-03, gap 99.0344%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 601.4715321063995\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.998761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.944238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNP-OCT</td>\n",
       "      <td>0.915737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighbors</td>\n",
       "      <td>0.909542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RadialSVM</td>\n",
       "      <td>0.895911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.887237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVM</td>\n",
       "      <td>0.881041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Classifier  Accuracy\n",
       "0      RandomForest  1.000000\n",
       "1      DecisionTree  1.000000\n",
       "2  GradientBoosting  0.998761\n",
       "3          AdaBoost  0.944238\n",
       "4           BNP-OCT  0.915737\n",
       "5        KNeighbors  0.909542\n",
       "6         RadialSVM  0.895911\n",
       "7          Logistic  0.887237\n",
       "8         LinearSVM  0.881041"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = acc_score(select_X_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation Of Below Cell\n",
    "\n",
    "Below, I'm running the GA with BNP-OCT as its base. Basically, using the 7 features already selected by XGBoost, the idea is the GA is being used for further feature selection here. Basically, what its doing is running over multiple possible feature combinations with BNP-OCT as the classifier that its exploring. The algorithm is selecting the most accurate BNP-OCT outputs with that, and continuing to recombine, mutate etc. Currently, its taking very long, because each generation has about 2 possible solutions being explored, and those are recombined for the next set, with each possible model taking 10 minutes to train, so all combination can take upto and 1 to an hour and half to run. Also, there's a posssibility that some solutions are invalid, so if we hit upon those in the GA, it means it came across an invalid solution. Currently, I'm fixing that by removing the mutation rate, and also trying to increase the set of explored parent solution beforem moving generations (as the greater the number of parent solutions, the greater chance that the GA will ignore some in the next generation, only selecting the correct ones, but its a balancing act of not having too many parents that training takes an absurd amount of time. With XGBoost, the number of required parents was 64, which is too large a number of BNP-OCT to explore with GA).\n",
    "\n",
    "## Next steps\n",
    "If this ends up not producing anything reasonable, I could try exploring GA on hyperparameters (but that would be a lot longer on implementation, as the GA would have to be altered in a fundamental way). \n",
    "\n",
    "Finally, we should check with Ted, if he wants GA to be used as an alternative to MILP, as that would probably be the multi-month project of delving into _base.py and tree.py and altering those algos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpvxjooct9.pyomo.lp\n",
      "Reading time = 0.13 seconds\n",
      "x1: 20786 rows, 6608 columns, 321527 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 20786 rows, 6608 columns and 321527 nonzeros\n",
      "Model fingerprint: 0xe1215e14\n",
      "Variable types: 6489 continuous, 119 integer (119 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 2810 rows and 1346 columns\n",
      "Presolve time: 1.09s\n",
      "Presolved: 17976 rows, 5262 columns, 275556 nonzeros\n",
      "Variable types: 5149 continuous, 113 integer (113 binary)\n",
      "Found heuristic solution: objective 1.0350000\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 3113 iterations, 1.68 seconds (2.52 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -    3s\n",
      "H    0     0                       0.8864045    0.00500  99.4%     -    3s\n",
      "     0     0    0.00500    0    8    0.88640    0.00500  99.4%     -   17s\n",
      "H    0     0                       0.8751685    0.00500  99.4%     -   19s\n",
      "     0     0    0.00500    0    8    0.87517    0.00500  99.4%     -   20s\n",
      "     0     0    0.00500    0    7    0.87517    0.00500  99.4%     -   45s\n",
      "H    0     0                       0.8689326    0.00500  99.4%     -   46s\n",
      "     0     0    0.00500    0    8    0.86893    0.00500  99.4%     -   50s\n",
      "     0     0    0.00500    0    6    0.86893    0.00500  99.4%     -   56s\n",
      "H    0     0                       0.8576966    0.00500  99.4%     -   56s\n",
      "     0     0    0.00500    0    6    0.85770    0.00500  99.4%     -   58s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   62s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   65s\n",
      "     0     0    0.00500    0    6    0.85770    0.00500  99.4%     -   71s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   76s\n",
      "     0     0    0.00500    0    7    0.85770    0.00500  99.4%     -   84s\n",
      "H    0     0                       0.7965169    0.00500  99.4%     -   89s\n",
      "     0     0    0.00500    0    6    0.79652    0.00500  99.4%     -   93s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -   98s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  101s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -  105s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -  109s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  114s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  115s\n",
      "     0     2    0.00500    0    5    0.79652    0.00500  99.4%     -  127s\n",
      "     1     4    0.00500    1    4    0.79652    0.00500  99.4%  1205  197s\n",
      "     3     8    0.00500    2    4    0.79652    0.00500  99.4% 17151  315s\n",
      "     7    12    0.00500    3    5    0.79652    0.00500  99.4% 19167  320s\n",
      "    11    16    0.00500    4    7    0.79652    0.00500  99.4% 13361  335s\n",
      "    19    24    0.00705    5   16    0.79652    0.00500  99.4% 15411  569s\n",
      "    23    30    0.00500    5    8    0.79652    0.00500  99.4% 13766  591s\n",
      "    29    32    0.35331    7    1    0.79652    0.00500  99.4% 11397  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 216\n",
      "  MIR: 48\n",
      "  Flow cover: 13\n",
      "  RLT: 3\n",
      "  Relax-and-lift: 138\n",
      "\n",
      "Explored 31 nodes (383710 simplex iterations) in 600.03 seconds (1069.01 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 7: 0.796517 0.857697 0.868933 ... 1.035\n",
      "\n",
      "Time limit reached\n",
      "Best objective 7.965168539326e-01, best bound 5.000000000000e-03, gap 99.3723%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 600.3965609073639\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpqx2lxoq8.pyomo.lp\n",
      "Reading time = 0.23 seconds\n",
      "x1: 19058 rows, 6608 columns, 272051 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 19058 rows, 6608 columns and 272051 nonzeros\n",
      "Model fingerprint: 0xb5c28ad1\n",
      "Variable types: 6489 continuous, 119 integer (119 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 3449 rows and 2075 columns\n",
      "Presolve time: 1.72s\n",
      "Presolved: 15609 rows, 4533 columns, 224020 nonzeros\n",
      "Variable types: 4420 continuous, 113 integer (113 binary)\n",
      "Found heuristic solution: objective 1.0350000\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 1279 iterations, 0.57 seconds (0.53 work units)\n",
      "Total elapsed time = 5.27s\n",
      "Total elapsed time = 10.29s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    5    1.00500    0.00500   100%     -   11s\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -   16s\n",
      "     0     0    0.00500    0    6    1.00500    0.00500   100%     -   17s\n",
      "H    0     0                       0.9875281    0.00500  99.5%     -   23s\n",
      "     0     0    0.00500    0    7    0.98753    0.00500  99.5%     -   23s\n",
      "     0     0    0.00500    0    6    0.98753    0.00500  99.5%     -   24s\n",
      "H    0     0                       0.9762921    0.00500  99.5%     -   29s\n",
      "     0     0    0.00500    0    7    0.97629    0.00500  99.5%     -   29s\n",
      "     0     0    0.00500    0    6    0.97629    0.00500  99.5%     -   31s\n",
      "     0     0    0.00500    0    5    0.97629    0.00500  99.5%     -   34s\n",
      "H    0     0                       0.9088764    0.00500  99.4%     -   37s\n",
      "     0     0    0.00500    0    4    0.90888    0.00500  99.4%     -   38s\n",
      "H    0     0                       0.8976404    0.00500  99.4%     -   42s\n",
      "     0     0    0.00500    0    4    0.89764    0.00500  99.4%     -   42s\n",
      "     0     0    0.00500    0    5    0.89764    0.00500  99.4%     -   44s\n",
      "     0     0    0.00500    0    6    0.89764    0.00500  99.4%     -   48s\n",
      "     0     0    0.00500    0    6    0.89764    0.00500  99.4%     -   48s\n",
      "H    0     0                       0.8414607    0.00500  99.4%     -   51s\n",
      "     0     2    0.00500    0    6    0.84146    0.00500  99.4%     -   51s\n",
      "     1     4    0.00679    1   13    0.84146    0.00500  99.4% 34967  111s\n",
      "     3     8    0.01212    2   27    0.84146    0.00501  99.4% 22156  116s\n",
      "     7    12    0.01812    3   15    0.84146    0.00504  99.4% 10563  120s\n",
      "    11    16    0.14034    3   10    0.84146    0.00844  99.0%  7276  128s\n",
      "    15    20    0.02117    4   18    0.84146    0.00844  99.0%  5875  152s\n",
      "    19    24    0.18978    4   11    0.84146    0.00844  99.0%  5188  159s\n",
      "    23    30    0.06419    5   15    0.84146    0.00844  99.0%  4827  165s\n",
      "    29    33 infeasible    6         0.84146    0.00844  99.0%  4298  188s\n",
      "H   31    33                       0.7740449    0.00844  98.9%  4033  188s\n",
      "H   31    33                       0.7678090    0.00844  98.9%  4033  188s\n",
      "    34    39    0.13360    8    9    0.76781    0.00844  98.9%  4513  194s\n",
      "    40    48    0.13360   10   11    0.76781    0.00844  98.9%  4300  206s\n",
      "    49    56 infeasible   11         0.76781    0.00844  98.9%  3913  214s\n",
      "    59    57    0.13840   13   16    0.76781    0.00844  98.9%  3723  226s\n",
      "    66    67    0.13360   13   10    0.76781    0.00844  98.9%  3518  233s\n",
      "    78    76    0.13860   16   10    0.76781    0.00844  98.9%  3161  238s\n",
      "    87    91    0.13860   18   12    0.76781    0.00844  98.9%  3017  257s\n",
      "H   91    91                       0.7678090    0.00844  98.9%  2912  257s\n",
      "   102   102    0.14020   20   14    0.76781    0.00844  98.9%  2835  262s\n",
      "   117   115    0.56342   23   14    0.76781    0.00844  98.9%  2574  271s\n",
      "   136   123 infeasible   26         0.76781    0.00844  98.9%  2317  282s\n",
      "   154   131    0.71399    7    4    0.76781    0.01000  98.7%  2234  298s\n",
      "   171   170    0.64455    7    7    0.76781    0.01000  98.7%  2209  335s\n",
      "   235   216    0.01500    8   17    0.76781    0.01000  98.7%  1958  376s\n",
      "   336   217 infeasible   30         0.76781    0.01000  98.7%  1550  428s\n",
      "   370   251    0.01064    4   22    0.76781    0.01000  98.7%  1674  447s\n",
      "   410   322    0.01500    4   29    0.76781    0.01000  98.7%  1616  482s\n",
      "   514   338    0.01500    5   14    0.76781    0.01000  98.7%  1375  565s\n",
      "   547   409    0.01552   12   18    0.76781    0.01000  98.7%  1515  577s\n",
      "   636   427    0.46320   33   11    0.76781    0.01000  98.7%  1385  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 447\n",
      "  MIR: 97\n",
      "  Flow cover: 16\n",
      "  RLT: 5\n",
      "  Relax-and-lift: 376\n",
      "\n",
      "Explored 685 nodes (946822 simplex iterations) in 600.05 seconds (697.37 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 0.767809 0.767809 0.774045 ... 1.035\n",
      "\n",
      "Time limit reached\n",
      "Best objective 7.678089885873e-01, best bound 1.000000000000e-02, gap 98.6976%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 600.5665769577026\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n",
      "Best score in generation 1 : [0.9169764560099133]\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpzrkw62f6.pyomo.lp\n",
      "Reading time = 0.32 seconds\n",
      "x1: 19058 rows, 6608 columns, 272051 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 19058 rows, 6608 columns and 272051 nonzeros\n",
      "Model fingerprint: 0xb5c28ad1\n",
      "Variable types: 6489 continuous, 119 integer (119 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 3449 rows and 2075 columns\n",
      "Presolve time: 1.82s\n",
      "Presolved: 15609 rows, 4533 columns, 224020 nonzeros\n",
      "Variable types: 4420 continuous, 113 integer (113 binary)\n",
      "Found heuristic solution: objective 1.0350000\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 1279 iterations, 0.81 seconds (0.53 work units)\n",
      "Total elapsed time = 6.62s\n",
      "Total elapsed time = 12.33s\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    5    1.00500    0.00500   100%     -   13s\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -   18s\n",
      "     0     0    0.00500    0    6    1.00500    0.00500   100%     -   19s\n",
      "H    0     0                       0.9875281    0.00500  99.5%     -   24s\n",
      "     0     0    0.00500    0    7    0.98753    0.00500  99.5%     -   24s\n",
      "     0     0    0.00500    0    6    0.98753    0.00500  99.5%     -   26s\n",
      "H    0     0                       0.9762921    0.00500  99.5%     -   29s\n",
      "     0     0    0.00500    0    7    0.97629    0.00500  99.5%     -   29s\n",
      "     0     0    0.00500    0    6    0.97629    0.00500  99.5%     -   31s\n",
      "     0     0    0.00500    0    5    0.97629    0.00500  99.5%     -   34s\n",
      "H    0     0                       0.9088764    0.00500  99.4%     -   36s\n",
      "     0     0    0.00500    0    4    0.90888    0.00500  99.4%     -   38s\n",
      "H    0     0                       0.8976404    0.00500  99.4%     -   43s\n",
      "     0     0    0.00500    0    4    0.89764    0.00500  99.4%     -   43s\n",
      "     0     0    0.00500    0    5    0.89764    0.00500  99.4%     -   46s\n",
      "     0     0    0.00500    0    6    0.89764    0.00500  99.4%     -   50s\n",
      "     0     0    0.00500    0    6    0.89764    0.00500  99.4%     -   50s\n",
      "H    0     0                       0.8414607    0.00500  99.4%     -   53s\n",
      "     0     2    0.00500    0    6    0.84146    0.00500  99.4%     -   53s\n",
      "     1     4    0.00679    1   13    0.84146    0.00500  99.4% 34967  116s\n",
      "     3     8    0.01212    2   27    0.84146    0.00501  99.4% 22156  121s\n",
      "     7    12    0.01812    3   15    0.84146    0.00504  99.4% 10563  125s\n",
      "    11    16    0.14034    3   10    0.84146    0.00844  99.0%  7276  132s\n",
      "    15    20    0.02117    4   18    0.84146    0.00844  99.0%  5875  151s\n",
      "    19    24    0.18978    4   11    0.84146    0.00844  99.0%  5188  160s\n",
      "    23    30    0.06419    5   15    0.84146    0.00844  99.0%  4827  167s\n",
      "    29    33 infeasible    6         0.84146    0.00844  99.0%  4298  185s\n",
      "H   31    33                       0.7740449    0.00844  98.9%  4033  185s\n",
      "H   31    33                       0.7678090    0.00844  98.9%  4033  185s\n",
      "    34    39    0.13360    8    9    0.76781    0.00844  98.9%  4513  191s\n",
      "    40    48    0.13360   10   11    0.76781    0.00844  98.9%  4300  211s\n",
      "    49    56 infeasible   11         0.76781    0.00844  98.9%  3913  225s\n",
      "    59    57    0.13840   13   16    0.76781    0.00844  98.9%  3723  237s\n",
      "    66    67    0.13360   13   10    0.76781    0.00844  98.9%  3518  241s\n",
      "    87    91    0.13860   18   12    0.76781    0.00844  98.9%  3017  255s\n",
      "H   91    91                       0.7678090    0.00844  98.9%  2912  255s\n",
      "   117   115    0.56342   23   14    0.76781    0.00844  98.9%  2574  267s\n",
      "   136   123 infeasible   26         0.76781    0.00844  98.9%  2317  277s\n",
      "   154   131    0.71399    7    4    0.76781    0.01000  98.7%  2234  288s\n",
      "   171   170    0.64455    7    7    0.76781    0.01000  98.7%  2209  317s\n",
      "   235   216    0.01500    8   17    0.76781    0.01000  98.7%  1958  347s\n",
      "   336   217 infeasible   30         0.76781    0.01000  98.7%  1550  398s\n",
      "   370   251    0.01064    4   22    0.76781    0.01000  98.7%  1674  414s\n",
      "   410   322    0.01500    4   29    0.76781    0.01000  98.7%  1616  445s\n",
      "   514   338    0.01500    5   14    0.76781    0.01000  98.7%  1375  542s\n",
      "   547   409    0.01552   12   18    0.76781    0.01000  98.7%  1515  557s\n",
      "   636   428    0.46320   33   11    0.76781    0.01000  98.7%  1385  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 447\n",
      "  MIR: 97\n",
      "  Flow cover: 16\n",
      "  RLT: 5\n",
      "  Relax-and-lift: 376\n",
      "\n",
      "Explored 686 nodes (957518 simplex iterations) in 600.04 seconds (716.63 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 0.767809 0.767809 0.774045 ... 1.035\n",
      "\n",
      "Time limit reached\n",
      "Best objective 7.678089885873e-01, best bound 1.000000000000e-02, gap 98.6976%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 600.7041120529175\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpg2s356oa.pyomo.lp\n",
      "Reading time = 0.26 seconds\n",
      "x1: 20786 rows, 6608 columns, 321527 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 20786 rows, 6608 columns and 321527 nonzeros\n",
      "Model fingerprint: 0xe1215e14\n",
      "Variable types: 6489 continuous, 119 integer (119 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 2810 rows and 1346 columns\n",
      "Presolve time: 1.76s\n",
      "Presolved: 17976 rows, 5262 columns, 275556 nonzeros\n",
      "Variable types: 5149 continuous, 113 integer (113 binary)\n",
      "Found heuristic solution: objective 1.0350000\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 3113 iterations, 2.35 seconds (2.52 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -    4s\n",
      "H    0     0                       0.8864045    0.00500  99.4%     -    5s\n",
      "     0     0    0.00500    0    8    0.88640    0.00500  99.4%     -   21s\n",
      "H    0     0                       0.8751685    0.00500  99.4%     -   22s\n",
      "     0     0    0.00500    0    8    0.87517    0.00500  99.4%     -   22s\n",
      "     0     0    0.00500    0    7    0.87517    0.00500  99.4%     -   43s\n",
      "H    0     0                       0.8689326    0.00500  99.4%     -   45s\n",
      "     0     0    0.00500    0    8    0.86893    0.00500  99.4%     -   50s\n",
      "     0     0    0.00500    0    6    0.86893    0.00500  99.4%     -   56s\n",
      "H    0     0                       0.8576966    0.00500  99.4%     -   57s\n",
      "     0     0    0.00500    0    6    0.85770    0.00500  99.4%     -   59s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   64s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   66s\n",
      "     0     0    0.00500    0    6    0.85770    0.00500  99.4%     -   72s\n",
      "     0     0    0.00500    0    5    0.85770    0.00500  99.4%     -   76s\n",
      "     0     0    0.00500    0    7    0.85770    0.00500  99.4%     -   83s\n",
      "H    0     0                       0.7965169    0.00500  99.4%     -   88s\n",
      "     0     0    0.00500    0    6    0.79652    0.00500  99.4%     -   92s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -   99s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  102s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -  107s\n",
      "     0     0    0.00500    0    4    0.79652    0.00500  99.4%     -  112s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  118s\n",
      "     0     0    0.00500    0    5    0.79652    0.00500  99.4%     -  119s\n",
      "     0     2    0.00500    0    5    0.79652    0.00500  99.4%     -  133s\n",
      "     1     4    0.00500    1    4    0.79652    0.00500  99.4%  1205  221s\n",
      "     3     8    0.00500    2    4    0.79652    0.00500  99.4% 17151  378s\n",
      "     7    12    0.00500    3    5    0.79652    0.00500  99.4% 19167  384s\n",
      "    11    16    0.00500    4    7    0.79652    0.00500  99.4% 13361  401s\n",
      "    19    23    0.49938    5    1    0.79652    0.00500  99.4%  8997  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 216\n",
      "  MIR: 48\n",
      "  Flow cover: 13\n",
      "  RLT: 3\n",
      "  Relax-and-lift: 138\n",
      "\n",
      "Explored 22 nodes (231757 simplex iterations) in 600.05 seconds (881.02 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 7: 0.796517 0.857697 0.868933 ... 1.035\n",
      "\n",
      "Time limit reached\n",
      "Best objective 7.965168539326e-01, best bound 5.000000000000e-03, gap 99.3723%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 600.6549937725067\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n",
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmp6futnwqr.pyomo.lp\n",
      "Reading time = 0.34 seconds\n",
      "x1: 22754 rows, 6615 columns, 355722 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 22754 rows, 6615 columns and 355722 nonzeros\n",
      "Model fingerprint: 0x4f058abd\n",
      "Variable types: 6489 continuous, 126 integer (126 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 2704 rows and 1226 columns\n",
      "Presolve time: 2.72s\n",
      "Presolved: 20050 rows, 5389 columns, 318324 nonzeros\n",
      "Variable types: 5269 continuous, 120 integer (120 binary)\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    1519    5.9311229e-03   5.106639e+03   0.000000e+00      5s\n",
      "    3450    5.0000000e-03   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 3450 iterations, 4.38 seconds (3.19 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -    7s\n",
      "H    0     0                       0.8914045    0.00500  99.4%     -    9s\n",
      "     0     0    0.00500    0    8    0.89140    0.00500  99.4%     -   21s\n",
      "     0     0    0.00500    0    8    0.89140    0.00500  99.4%     -   24s\n",
      "     0     0    0.00500    0    9    0.89140    0.00500  99.4%     -   42s\n",
      "     0     0    0.00500    0    6    0.89140    0.00500  99.4%     -   48s\n",
      "     0     0    0.00500    0    6    0.89140    0.00500  99.4%     -   58s\n",
      "H    0     0                       0.8801685    0.00500  99.4%     -   58s\n",
      "     0     0    0.00500    0    8    0.88017    0.00500  99.4%     -   68s\n",
      "     0     0    0.00500    0    6    0.88017    0.00500  99.4%     -   85s\n",
      "H    0     0                       0.8352247    0.00500  99.4%     -   86s\n",
      "     0     0    0.00500    0    5    0.83522    0.00500  99.4%     -  102s\n",
      "     0     0    0.00500    0    6    0.83522    0.00500  99.4%     -  112s\n",
      "     0     0    0.00500    0    5    0.83522    0.00500  99.4%     -  120s\n",
      "     0     0    0.00500    0    5    0.83522    0.00500  99.4%     -  128s\n",
      "H    0     0                       0.8239888    0.00500  99.4%     -  131s\n",
      "     0     0    0.00500    0    5    0.82399    0.00500  99.4%     -  135s\n",
      "     0     0    0.00500    0    5    0.82399    0.00500  99.4%     -  140s\n",
      "     0     0    0.00500    0    5    0.82399    0.00500  99.4%     -  141s\n",
      "H    0     0                       0.8015169    0.00500  99.4%     -  152s\n",
      "     0     2    0.00500    0    5    0.80152    0.00500  99.4%     -  152s\n",
      "     1     4    0.00500    1    7    0.80152    0.00500  99.4%  3046  258s\n",
      "     3     8    0.00833    2   11    0.80152    0.00500  99.4% 36436  358s\n",
      "     7    12    0.03463    3   30    0.80152    0.00502  99.4% 23705  374s\n",
      "    11    16    0.01000    3    9    0.80152    0.00502  99.4% 16214  383s\n",
      "    15    20    0.01000    4   10    0.80152    0.00502  99.4% 12688  500s\n",
      "    19    23    0.01000    5    7    0.80152    0.00502  99.4% 11941  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 236\n",
      "  MIR: 82\n",
      "  Flow cover: 20\n",
      "  RLT: 8\n",
      "  Relax-and-lift: 157\n",
      "\n",
      "Explored 22 nodes (274545 simplex iterations) in 600.05 seconds (671.40 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 6: 0.801517 0.823989 0.835225 ... 1.005\n",
      "\n",
      "Time limit reached\n",
      "Best objective 8.015168539326e-01, best bound 5.021828946485e-03, gap 99.3735%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 600.7961161136627\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n",
      "Best score in generation 2 : [0.9169764560099133]\n"
     ]
    }
   ],
   "source": [
    "# Run the GA\n",
    "logmodel = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"gurobi\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'mip_focus': mip_focus,\n",
    "                                                  'mip_polish_time': mip_polish_time,\n",
    "                                                  }\n",
    "                                  )\n",
    "# X_train,X_test, Y_train, Y_test = split(X, y)\n",
    "chromo_df_bc,score_bc=generations(select_X_train,y_train,size=2,n_feat=select_X_train.shape[1],n_parents=2,mutation_rate=0.00,n_gen=2,\n",
    "                         X_train = select_X_train,X_test = select_X_train,Y_train = y_train,Y_test = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ True,  True,  True,  True,  True, False, False]), array([ True,  True,  True,  True,  True, False, False])]\n",
      "['periodadmt', 'alife', 'provider_NoOfMonths_PartACov_mean', 'provider_InscClaimAmtReimbursed_std', 'provider_NoOfMonths_PartBCov_std', 'provider_IPAnnualDeductibleAmt_std', 'provider_OPAnnualDeductibleAmt_std']\n"
     ]
    }
   ],
   "source": [
    "# Select the features indicated by the GA\n",
    "print(chromo_df_bc)\n",
    "print(names)\n",
    "# names = []\n",
    "# select_X_train = []\n",
    "# for i in range(len(chromo_df_bc[2])):\n",
    "#     if chromo_df_bc[2][i] == True:\n",
    "#         names.append(fraud_data.iloc[:, [i]].columns[0])\n",
    "#         select_X_train.append(X_train[:, i])\n",
    "# select_X_train = np.asarray(select_X_train).T\n",
    "# print(len(names))\n",
    "# print(select_X_train.shape)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 5)\n",
      "(807, 7)\n"
     ]
    }
   ],
   "source": [
    "names_1 = []\n",
    "select_X_train_1 = []\n",
    "for i in range(len(chromo_df_bc[1])):\n",
    "    if chromo_df_bc[1][i] == True:\n",
    "        names_1.append(names[i])\n",
    "        select_X_train_1.append(select_X_train[:, i])\n",
    "select_X_train_1 = np.asarray(select_X_train_1).T\n",
    "print(select_X_train_1.shape)\n",
    "print(select_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lsopt.tree import OptimalTreeClassifier ## M-OCT propsed by Liu & Allen\n",
    "from lsopt.tree import BinNodePenaltyOptimalTreeClassifier ## BNP-OCT propsed by Liu & Allen\n",
    "# selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "# select_X_train = selection.transform(X_train)\n",
    "\n",
    "# OCT parameters\n",
    "max_depth = 5\n",
    "min_samples_leaf = 1\n",
    "alpha = 0.005\n",
    "time_limit = 10  # minute\n",
    "mip_gap_tol = 0.05  # optimal gap percentage\n",
    "mip_focus = 'balance'\n",
    "mip_polish_time = None\n",
    "fp_heur = True\n",
    "backtrack = \"bestb\"\n",
    "\n",
    "warm_start = False\n",
    "log_file = None\n",
    "\n",
    "\n",
    "\n",
    "# Construct BNP-OCT classifier\n",
    "selection_model = BinNodePenaltyOptimalTreeClassifier(max_depth=max_depth,min_samples_leaf=min_samples_leaf,\n",
    "                                  alpha=alpha,\n",
    "                                  criterion=\"gini\",\n",
    "                                  solver=\"gurobi\",\n",
    "                                  time_limit=time_limit,\n",
    "                                  verbose=True,\n",
    "                                  warm_start=warm_start,\n",
    "                                  log_file=log_file,\n",
    "                                  solver_options={'mip_cuts': None,\n",
    "                                                  'mip_gap_tol': mip_gap_tol,\n",
    "                                                  'mip_focus': mip_focus,\n",
    "                                                  'mip_polish_time': mip_polish_time,\n",
    "                                                  }\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter WLSAccessID\n",
      "Set parameter WLSSecret\n",
      "Set parameter LicenseID to value 2433923\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Read LP format model from file /var/folders/kb/sxk47lqj0xd8j0x92mykb0rr0000gn/T/tmpf7uoqaql.pyomo.lp\n",
      "Reading time = 1.94 seconds\n",
      "x1: 104890 rows, 26480 columns, 1723863 nonzeros\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-1038NG7 CPU @ 2.00GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "WLS license - registered to pranav.chaudhary@sagataltd.io\n",
      "Optimize a model with 104890 rows, 26480 columns and 1723863 nonzeros\n",
      "Model fingerprint: 0x0ac47df0\n",
      "Variable types: 25953 continuous, 527 integer (527 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [5e-03, 1e-02]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+03]\n",
      "Presolve removed 1694 rows and 51 columns (presolve time = 5s) ...\n",
      "Presolve removed 10886 rows and 9490 columns (presolve time = 10s) ...\n",
      "Presolve removed 9457 rows and 8053 columns\n",
      "Presolve time: 13.94s\n",
      "Presolved: 95433 rows, 18427 columns, 1353889 nonzeros\n",
      "Variable types: 17918 continuous, 509 integer (509 binary)\n",
      "Found heuristic solution: objective 1.0050000\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex (primal and dual model)\n",
      "Showing first log only...\n",
      "\n",
      "Root relaxation presolved: 95433 rows, 18427 columns, 1353889 nonzeros\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    5.0000000e-03   1.800000e+01   2.167969e+07     18s\n",
      "    1979    7.9232556e-01   0.000000e+00   3.857194e+04     20s\n",
      "    4419    5.0000114e-03   0.000000e+00   1.265125e-01     25s\n",
      "    4898    5.0000000e-03   0.000000e+00   0.000000e+00     27s\n",
      "Concurrent spin time: 4.82s\n",
      "\n",
      "Solved with primal simplex (primal model)\n",
      "\n",
      "Root relaxation: objective 5.000000e-03, 4898 iterations, 15.95 seconds (12.77 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00500    0    8    1.00500    0.00500   100%     -   32s\n",
      "H    0     0                       0.9538202    0.00500  99.5%     -   44s\n",
      "H    0     0                       0.9313483    0.00500  99.5%     -   44s\n",
      "     0     0          -    0         0.93135    0.00500  99.5%     -  600s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 24\n",
      "  MIR: 98\n",
      "  Flow cover: 45\n",
      "  RLT: 2\n",
      "  Relax-and-lift: 8\n",
      "\n",
      "Explored 1 nodes (65491 simplex iterations) in 600.05 seconds (894.42 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 0.931348 0.95382 1.005 \n",
      "\n",
      "Time limit reached\n",
      "Best objective 9.313483146067e-01, best bound 5.000000000000e-03, gap 99.4631%\n",
      "WARNING: Loading a SolverResults object with an 'aborted' status, but\n",
      "containing a solution\n",
      "Solver running time: 602.5971121788025\n",
      "Solver termination condition: maxTimeLimit\n",
      "Valid Tree : Yes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lsopt.tree.BinNodePenaltyOptimalTreeClassifier at 0x14c8b3a10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection_model.fit(select_X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'optimal_tree_fraud.png'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction\n",
    "# selection = SelectFromModel(model, threshold=true_thresh, prefit=True)\n",
    "# select_X_test = selection.transform(X_test)\n",
    "y_pred = selection_model.predict(X=select_X_train_1)\n",
    "y_pred_prob = selection_model.predict_proba(X=select_X_train_1)\n",
    "\n",
    "# Check confusion matrix\n",
    "# print(\"Confusion Matrix :\")\n",
    "# print(confusion_matrix(y_true=y_test,\n",
    "#                        y_pred=y_pred))\n",
    "\n",
    "# print(classification_report(y_true=y_test,\n",
    "#                             y_pred=y_pred))\n",
    "\n",
    "# Plot Optimal Tree\n",
    "feature_names = names_1\n",
    "class_names = ['Not-Fraud', 'Fraud']\n",
    "\n",
    "dot_data = tree.export_graphviz(selection_model,\n",
    "                                out_file=None,\n",
    "                                feature_names=feature_names,\n",
    "                                class_names=class_names,\n",
    "                                label='all',\n",
    "                                impurity=True,\n",
    "                                node_ids=True,\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                leaves_parallel=True,\n",
    "                                special_characters=False)\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.format = 'png'\n",
    "graph.render(filename='optimal_tree_fraud', directory='', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in y_pred:\n",
    "    if element == 1:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lsopt.tree.BinNodePenaltyOptimalTreeClassifier object at 0x12ead3e90>\n"
     ]
    }
   ],
   "source": [
    "print(selection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image('optimal_tree_fraud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'solve_oct_MILP_BIN.<locals>.obj_rule'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\sagata\\Assurance\\optimaltree-master\\boost.ipynb Cell 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/sagata/Assurance/optimaltree-master/boost.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     pickle\u001b[39m.\u001b[39;49mdump(selection_model, file)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'solve_oct_MILP_BIN.<locals>.obj_rule'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model_pkl', 'wb') as file:\n",
    "    pickle.dump(selection_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
